# FinOps AWS - Guia TÃ©cnico Completo

## Ãndice Detalhado

1. [IntroduÃ§Ã£o e Contexto](#1-introduÃ§Ã£o-e-contexto)
2. [VisÃ£o Geral da Arquitetura](#2-visÃ£o-geral-da-arquitetura)
3. [Arquitetura Step Functions + S3](#3-arquitetura-step-functions--s3)
4. [PadrÃµes de Projeto Aplicados](#4-padrÃµes-de-projeto-aplicados)
5. [Estrutura de Camadas](#5-estrutura-de-camadas)
6. [Componentes Core Detalhados](#6-componentes-core-detalhados)
7. [Camada de ServiÃ§os AWS](#7-camada-de-serviÃ§os-aws)
8. [Fluxo de ExecuÃ§Ã£o Completo](#8-fluxo-de-execuÃ§Ã£o-completo)
9. [Gerenciamento de Estado com S3](#9-gerenciamento-de-estado-com-s3)
10. [ResiliÃªncia e Mecanismos de Retry](#10-resiliÃªncia-e-mecanismos-de-retry)
11. [IntegraÃ§Ã£o AWS Lambda e Step Functions](#11-integraÃ§Ã£o-aws-lambda-e-step-functions)
12. [SeguranÃ§a e Compliance](#12-seguranÃ§a-e-compliance)
13. [Testes e Qualidade de Software](#13-testes-e-qualidade-de-software)
14. [Infraestrutura como CÃ³digo (Terraform)](#14-infraestrutura-como-cÃ³digo-terraform)
15. [Modelos de Dados e Dataclasses](#15-modelos-de-dados-e-dataclasses)
16. [APIs e Interfaces](#16-apis-e-interfaces)
17. [Performance e OtimizaÃ§Ãµes](#17-performance-e-otimizaÃ§Ãµes)
18. [Troubleshooting e Debugging](#18-troubleshooting-e-debugging)
19. [ApÃªndices TÃ©cnicos](#19-apÃªndices-tÃ©cnicos)

---

# 1. IntroduÃ§Ã£o e Contexto

## 1.1 PropÃ³sito deste Documento

Este guia tÃ©cnico destina-se a **arquitetos de software**, **engenheiros de plataforma** e **desenvolvedores senior** que precisam compreender profundamente a implementaÃ§Ã£o do FinOps AWS. O documento detalha cada componente, padrÃ£o de projeto, decisÃ£o arquitetural e fluxo de dados da soluÃ§Ã£o.

## 1.2 Escopo TÃ©cnico

O FinOps AWS Ã© uma soluÃ§Ã£o **enterprise-grade** para anÃ¡lise de custos AWS com as seguintes caracterÃ­sticas tÃ©cnicas:

| CaracterÃ­stica | EspecificaÃ§Ã£o |
|----------------|---------------|
| **Linguagem** | Python 3.11 |
| **Arquitetura** | Clean Architecture + DDD |
| **ServiÃ§os Cobertos** | 253 serviÃ§os AWS |
| **Infraestrutura** | Serverless (Lambda + Step Functions + S3) |
| **Testes** | 2.013 testes automatizados |
| **Taxa de Sucesso** | 99,6% (7 testes skipped por limitaÃ§Ãµes Moto) |
| **Terraform LOC** | 3.006 linhas |
| **ExecuÃ§Ãµes DiÃ¡rias** | Otimizado para 100/dia |

## 1.3 Filosofia de Design

A soluÃ§Ã£o segue princÃ­pios fundamentais de engenharia de software:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRINCÃPIOS DE DESIGN                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   SOLID         â”‚   â”‚  Clean Code     â”‚   â”‚  12-Factor      â”‚           â”‚
â”‚  â”‚  Principles     â”‚   â”‚   Practices     â”‚   â”‚    App          â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â”‚                     â”‚                     â”‚                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚            â”‚   CLEAN ARCHITECTURE        â”‚                                  â”‚
â”‚            â”‚  + Domain-Driven Design     â”‚                                  â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                          â”‚                                                  â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚           â–¼              â–¼              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ Separation  â”‚  â”‚ Dependency  â”‚  â”‚ Testability â”‚                         â”‚
â”‚  â”‚ of Concerns â”‚  â”‚ Inversion   â”‚  â”‚    First    â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 2. VisÃ£o Geral da Arquitetura

## 2.1 Diagrama de Arquitetura de Alto NÃ­vel

```mermaid
graph TB
    subgraph "Camada de Entrada"
        A[AWS EventBridge<br/>Scheduler] 
        B[API Gateway<br/>REST API]
        C[CLI Local<br/>Desenvolvimento]
    end
    
    subgraph "Camada de OrquestraÃ§Ã£o"
        D[AWS Step Functions<br/>State Machine]
        E[Lambda Mapper<br/>DivisÃ£o de Batches]
        F[Lambda Workers<br/>Processamento Paralelo]
        G[Lambda Aggregator<br/>ConsolidaÃ§Ã£o]
    end
    
    subgraph "Camada de ServiÃ§os"
        H[ServiceFactory<br/>253 ServiÃ§os]
        I[ResilientExecutor<br/>Circuit Breaker]
        J[RetryHandler<br/>Exponential Backoff]
    end
    
    subgraph "Camada de PersistÃªncia"
        K[S3 StateManager<br/>Estado + Reports]
        L[SQS Dead Letter<br/>Mensagens Falhas]
    end
    
    subgraph "AWS Cloud - 253 ServiÃ§os"
        M[EC2, Lambda, S3]
        N[RDS, DynamoDB, Aurora]
        O[VPC, ELB, CloudFront]
        P[IAM, KMS, Security Hub]
        Q[SageMaker, Bedrock]
        R[+ 243 outros serviÃ§os]
    end
    
    A --> D
    B --> D
    C --> H
    D --> E
    E --> F
    F --> G
    F --> H
    H --> I
    I --> J
    J --> M & N & O & P & Q & R
    G --> K
    F --> L
    
    style A fill:#ff9900,color:#fff
    style D fill:#cc66ff,color:#fff
    style H fill:#00d4aa,color:#fff
    style K fill:#3b48cc,color:#fff
```

## 2.2 Diagrama de Contexto (C4 Model - Level 1)

```mermaid
graph TB
    subgraph "UsuÃ¡rios"
        U1[ğŸ‘¤ Cloud Architect]
        U2[ğŸ‘¤ FinOps Engineer]
        U3[ğŸ‘¤ DevOps Engineer]
        U4[ğŸ‘¤ Finance Manager]
    end
    
    subgraph "Sistema FinOps AWS"
        SYS[ğŸ›ï¸ FinOps AWS<br/>SoluÃ§Ã£o de AnÃ¡lise<br/>de Custos]
    end
    
    subgraph "Sistemas Externos"
        AWS[â˜ï¸ AWS Cloud<br/>253 ServiÃ§os]
        S3_EXT[ğŸ“¦ S3<br/>Storage]
        CW[ğŸ“Š CloudWatch<br/>MÃ©tricas]
        CE[ğŸ’° Cost Explorer<br/>Custos]
        SNS[ğŸ“§ SNS<br/>NotificaÃ§Ãµes]
    end
    
    U1 & U2 & U3 & U4 --> SYS
    SYS --> AWS
    SYS --> S3_EXT
    SYS --> CW
    SYS --> CE
    SYS --> SNS
```

## 2.3 CaracterÃ­sticas Arquiteturais

| CaracterÃ­stica | ImplementaÃ§Ã£o | BenefÃ­cio |
|----------------|---------------|-----------|
| **Serverless** | Lambda + Step Functions | Zero gestÃ£o de servidores, escala automÃ¡tica |
| **Event-Driven** | EventBridge + Step Functions | Desacoplamento, resiliÃªncia |
| **Stateless** | S3 para estado | Escalabilidade horizontal ilimitada |
| **Fault-Tolerant** | Circuit Breaker + Retry | RecuperaÃ§Ã£o automÃ¡tica de falhas |
| **Observable** | CloudWatch + X-Ray | Visibilidade completa de execuÃ§Ã£o |
| **Cost-Optimized** | ~$3/mÃªs para 100 execuÃ§Ãµes | ROI imediato |

---

# 3. Arquitetura Step Functions + S3

## 3.1 Por que Step Functions + S3?

A arquitetura foi otimizada para **100 execuÃ§Ãµes diÃ¡rias** com custo mÃ­nimo:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPARATIVO DE ARQUITETURAS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  OpÃ§Ã£o A: Lambda MonolÃ­tico                                                 â”‚
â”‚  â”œâ”€â”€ Problema: Timeout de 15 min insuficiente para 253 serviÃ§os            â”‚
â”‚  â””â”€â”€ Custo: Alto (execuÃ§Ã£o longa contÃ­nua)                                 â”‚
â”‚                                                                             â”‚
â”‚  OpÃ§Ã£o B: DynamoDB + Lambda                                                 â”‚
â”‚  â”œâ”€â”€ Problema: Custo fixo de DynamoDB (~$25/mÃªs mÃ­nimo)                    â”‚
â”‚  â””â”€â”€ Excesso para 100 execuÃ§Ãµes/dia                                        â”‚
â”‚                                                                             â”‚
â”‚  âœ… OpÃ§Ã£o C: Step Functions + S3 (ESCOLHIDA)                                â”‚
â”‚  â”œâ”€â”€ Vantagem: OrquestraÃ§Ã£o nativa de workflows                            â”‚
â”‚  â”œâ”€â”€ Vantagem: S3 praticamente gratuito para este volume                   â”‚
â”‚  â”œâ”€â”€ Vantagem: Paralelismo built-in do Step Functions                      â”‚
â”‚  â””â”€â”€ Custo: ~$3/mÃªs para 100 execuÃ§Ãµes/dia                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 3.2 Fluxo de ExecuÃ§Ã£o Step Functions

```mermaid
stateDiagram-v2
    [*] --> MapperLambda: EventBridge Trigger
    
    MapperLambda --> ParallelProcessing: Divide 253 serviÃ§os em batches
    
    state ParallelProcessing {
        [*] --> Worker1: Batch 1 (50 serviÃ§os)
        [*] --> Worker2: Batch 2 (50 serviÃ§os)
        [*] --> Worker3: Batch 3 (50 serviÃ§os)
        [*] --> Worker4: Batch 4 (50 serviÃ§os)
        [*] --> Worker5: Batch 5 (53 serviÃ§os)
        
        Worker1 --> [*]
        Worker2 --> [*]
        Worker3 --> [*]
        Worker4 --> [*]
        Worker5 --> [*]
    }
    
    ParallelProcessing --> AggregatorLambda: Todos batches concluÃ­dos
    AggregatorLambda --> SaveToS3: Consolidar resultados
    SaveToS3 --> SendNotification: SNS Alert
    SendNotification --> [*]
    
    ParallelProcessing --> DLQ: Falha apÃ³s retries
    DLQ --> [*]
```

## 3.3 DefiniÃ§Ã£o do State Machine (ASL)

```json
{
  "Comment": "FinOps AWS - AnÃ¡lise de Custos e OtimizaÃ§Ã£o",
  "StartAt": "MapServices",
  "States": {
    "MapServices": {
      "Type": "Task",
      "Resource": "${LambdaMapperArn}",
      "ResultPath": "$.batches",
      "Next": "ProcessBatches"
    },
    "ProcessBatches": {
      "Type": "Map",
      "ItemsPath": "$.batches",
      "MaxConcurrency": 5,
      "Iterator": {
        "StartAt": "ProcessBatch",
        "States": {
          "ProcessBatch": {
            "Type": "Task",
            "Resource": "${LambdaWorkerArn}",
            "Retry": [
              {
                "ErrorEquals": ["States.TaskFailed", "Lambda.ServiceException"],
                "IntervalSeconds": 2,
                "MaxAttempts": 3,
                "BackoffRate": 2.0
              }
            ],
            "Catch": [
              {
                "ErrorEquals": ["States.ALL"],
                "ResultPath": "$.error",
                "Next": "HandleError"
              }
            ],
            "End": true
          },
          "HandleError": {
            "Type": "Task",
            "Resource": "${LambdaDLQArn}",
            "End": true
          }
        }
      },
      "ResultPath": "$.batchResults",
      "Next": "Aggregate"
    },
    "Aggregate": {
      "Type": "Task",
      "Resource": "${LambdaAggregatorArn}",
      "ResultPath": "$.finalReport",
      "Next": "Notify"
    },
    "Notify": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn": "${SNSTopicArn}",
        "Message.$": "$.finalReport.summary"
      },
      "End": true
    }
  }
}
```

## 3.4 Componentes Lambda

### 3.4.1 Lambda Mapper

```python
def mapper_handler(event: Dict, context: Any) -> Dict:
    """
    Divide os 253 serviÃ§os AWS em batches para processamento paralelo.
    
    EstratÃ©gia de divisÃ£o:
    - 5 batches de ~50 serviÃ§os cada
    - Balanceamento por complexidade (serviÃ§os pesados distribuÃ­dos)
    - PriorizaÃ§Ã£o de serviÃ§os crÃ­ticos no primeiro batch
    
    Returns:
        Dict com lista de batches para o Step Functions Map
    """
    all_services = ServiceFactory.get_all_service_types()  # 253 serviÃ§os
    
    # Classificar por prioridade e complexidade
    high_priority = ['ec2', 'rds', 's3', 'lambda', 'eks']
    medium_priority = ['dynamodb', 'elasticache', 'cloudfront', 'elb']
    
    # Criar batches balanceados
    batch_size = 50
    batches = []
    
    # Primeiro batch: serviÃ§os de alta prioridade
    batch1 = [s for s in all_services if s in high_priority]
    batch1.extend([s for s in all_services if s in medium_priority])
    
    # Demais batches: distribuiÃ§Ã£o uniforme
    remaining = [s for s in all_services if s not in batch1]
    for i in range(0, len(remaining), batch_size):
        batches.append({
            'batch_id': len(batches) + 1,
            'services': remaining[i:i+batch_size],
            'execution_id': event.get('execution_id', str(uuid.uuid4()))
        })
    
    # Inserir batch de alta prioridade no inÃ­cio
    batches.insert(0, {
        'batch_id': 0,
        'services': batch1[:batch_size],
        'execution_id': event.get('execution_id')
    })
    
    return {'batches': batches, 'total_services': len(all_services)}
```

### 3.4.2 Lambda Worker

```python
def worker_handler(event: Dict, context: Any) -> Dict:
    """
    Processa um batch de serviÃ§os AWS.
    
    Para cada serviÃ§o no batch:
    1. Health check - verifica disponibilidade
    2. Analyze usage - coleta mÃ©tricas de uso
    3. Get recommendations - gera recomendaÃ§Ãµes
    4. Salva checkpoint no S3
    
    Implementa:
    - Circuit Breaker por serviÃ§o
    - Retry com exponential backoff
    - Checkpointing para resumabilidade
    """
    batch = event['services']
    execution_id = event['execution_id']
    
    # Inicializar componentes
    client_factory = AWSClientFactory()
    service_factory = ServiceFactory(client_factory)
    state_manager = S3StateManager(execution_id)
    executor = ResilientExecutor(service_factory, state_manager)
    
    results = []
    
    for service_name in batch:
        try:
            # Verificar checkpoint existente
            if state_manager.is_service_completed(service_name):
                results.append(state_manager.get_service_result(service_name))
                continue
            
            # Obter serviÃ§o
            service = service_factory.get_service(service_name)
            
            # Executar com resiliÃªncia
            result = executor.execute_with_retry(
                service_name=service_name,
                operations=[
                    ('health_check', service.health_check),
                    ('analyze_usage', service.analyze_usage),
                    ('get_recommendations', service.get_recommendations)
                ]
            )
            
            # Salvar checkpoint
            state_manager.save_service_checkpoint(service_name, result)
            results.append(result)
            
        except CircuitBreakerOpenError:
            # Circuit aberto - registrar e continuar
            results.append({
                'service': service_name,
                'status': 'circuit_open',
                'error': 'Service temporarily unavailable'
            })
        except Exception as e:
            # Erro nÃ£o recuperÃ¡vel
            results.append({
                'service': service_name,
                'status': 'failed',
                'error': str(e)
            })
    
    return {
        'batch_id': event['batch_id'],
        'results': results,
        'completed': len([r for r in results if r.get('status') != 'failed']),
        'failed': len([r for r in results if r.get('status') == 'failed'])
    }
```

### 3.4.3 Lambda Aggregator

```python
def aggregator_handler(event: Dict, context: Any) -> Dict:
    """
    Consolida resultados de todos os batches e gera relatÃ³rio final.
    
    Processamento:
    1. Agregar resultados de todos os workers
    2. Calcular mÃ©tricas consolidadas
    3. Priorizar recomendaÃ§Ãµes por impacto
    4. Gerar relatÃ³rio executivo
    5. Salvar no S3
    """
    batch_results = event['batchResults']
    execution_id = event.get('execution_id', str(uuid.uuid4()))
    
    # Consolidar todos os resultados
    all_results = []
    for batch in batch_results:
        all_results.extend(batch.get('results', []))
    
    # Calcular mÃ©tricas
    total_services = len(all_results)
    successful = len([r for r in all_results if r.get('status') == 'healthy'])
    failed = len([r for r in all_results if r.get('status') == 'failed'])
    
    # Agregar recomendaÃ§Ãµes
    all_recommendations = []
    for result in all_results:
        recs = result.get('recommendations', [])
        all_recommendations.extend(recs)
    
    # Priorizar por economia potencial
    prioritized = sorted(
        all_recommendations,
        key=lambda r: r.get('estimated_savings', 0),
        reverse=True
    )
    
    # Calcular economia total
    total_savings = sum(r.get('estimated_savings', 0) for r in prioritized)
    
    # Gerar relatÃ³rio
    report = {
        'execution_id': execution_id,
        'timestamp': datetime.utcnow().isoformat(),
        'summary': {
            'services_analyzed': total_services,
            'services_healthy': successful,
            'services_failed': failed,
            'success_rate': f"{(successful/total_services)*100:.1f}%",
            'total_recommendations': len(prioritized),
            'total_potential_savings': total_savings,
            'top_10_recommendations': prioritized[:10]
        },
        'detailed_results': all_results,
        'all_recommendations': prioritized
    }
    
    # Salvar no S3
    s3_client = boto3.client('s3')
    bucket = os.environ['REPORTS_BUCKET']
    
    # Salvar relatÃ³rio completo
    s3_client.put_object(
        Bucket=bucket,
        Key=f"reports/{execution_id}/full_report.json",
        Body=json.dumps(report, indent=2, default=str),
        ContentType='application/json'
    )
    
    # Salvar resumo executivo
    s3_client.put_object(
        Bucket=bucket,
        Key=f"reports/{execution_id}/executive_summary.json",
        Body=json.dumps(report['summary'], indent=2, default=str),
        ContentType='application/json'
    )
    
    # Atualizar "latest"
    s3_client.put_object(
        Bucket=bucket,
        Key="reports/latest/report.json",
        Body=json.dumps(report, indent=2, default=str),
        ContentType='application/json'
    )
    
    return {
        'execution_id': execution_id,
        'report_location': f"s3://{bucket}/reports/{execution_id}/",
        'summary': report['summary']
    }
```

---

# 4. PadrÃµes de Projeto Aplicados

## 4.1 CatÃ¡logo de PadrÃµes

A soluÃ§Ã£o implementa os seguintes padrÃµes de projeto de software:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PADRÃ•ES DE PROJETO IMPLEMENTADOS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  CREATIONAL PATTERNS                                                        â”‚
â”‚  â”œâ”€â”€ Factory Method â”€â”€â”€â”€â”€â”€â”€ ServiceFactory, AWSClientFactory                â”‚
â”‚  â”œâ”€â”€ Abstract Factory â”€â”€â”€â”€â”€ CriaÃ§Ã£o de famÃ­lias de serviÃ§os               â”‚
â”‚  â””â”€â”€ Singleton â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ServiceFactory._instance (cache global)        â”‚
â”‚                                                                             â”‚
â”‚  STRUCTURAL PATTERNS                                                        â”‚
â”‚  â”œâ”€â”€ Decorator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ @with_retry, @with_metrics                     â”‚
â”‚  â”œâ”€â”€ Facade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ResilientExecutor (simplifica orquestraÃ§Ã£o)   â”‚
â”‚  â””â”€â”€ Adapter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AWSClientFactory (adapta boto3)               â”‚
â”‚                                                                             â”‚
â”‚  BEHAVIORAL PATTERNS                                                        â”‚
â”‚  â”œâ”€â”€ Template Method â”€â”€â”€â”€â”€â”€ BaseAWSService (interface comum)               â”‚
â”‚  â”œâ”€â”€ Strategy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RetryPolicy (polÃ­ticas configurÃ¡veis)          â”‚
â”‚  â”œâ”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Circuit Breaker (CLOSED/OPEN/HALF_OPEN)       â”‚
â”‚  â”œâ”€â”€ Observer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Metrics callbacks                              â”‚
â”‚  â””â”€â”€ Command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task encapsulation                             â”‚
â”‚                                                                             â”‚
â”‚  ENTERPRISE PATTERNS                                                        â”‚
â”‚  â”œâ”€â”€ Circuit Breaker â”€â”€â”€â”€â”€â”€ ProteÃ§Ã£o contra falhas em cascata             â”‚
â”‚  â”œâ”€â”€ Retry with Backoff â”€â”€â”€ RecuperaÃ§Ã£o de falhas transitÃ³rias            â”‚
â”‚  â”œâ”€â”€ Bulkhead â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Isolamento por serviÃ§o                         â”‚
â”‚  â””â”€â”€ Saga â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CompensaÃ§Ã£o em Step Functions                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4.2 Factory Pattern - ServiceFactory

```mermaid
classDiagram
    class ServiceFactory {
        -_instance: ServiceFactory
        -_services_cache: Dict
        -_mocks: Dict
        +client_factory: AWSClientFactory
        +get_instance() ServiceFactory
        +get_ec2_service() EC2Service
        +get_lambda_service() LambdaService
        +get_s3_service() S3Service
        +get_rds_service() RDSService
        +get_all_services() Dict
        +register_mock(service, mock) void
        +clear_cache() void
    }
    
    class AWSClientFactory {
        +region: str
        -_clients: Dict
        -_session: Session
        +get_client(service_type) Client
        +get_resource(service_type) Resource
    }
    
    class BaseAWSService {
        <<abstract>>
        +client_factory: AWSClientFactory
        +logger: Logger
        +health_check()* Dict
        +analyze_usage()* Dict
        +get_recommendations()* List
        +get_resources()* Dict
        +get_metrics()* Dict
    }
    
    class EC2Service {
        -_ec2_client: EC2Client
        -_cloudwatch: CloudWatchClient
        +health_check() Dict
        +analyze_usage() Dict
        +get_recommendations() List
    }
    
    class LambdaService {
        -_lambda_client: LambdaClient
        +health_check() Dict
        +analyze_usage() Dict
        +get_recommendations() List
    }
    
    ServiceFactory --> AWSClientFactory
    ServiceFactory --> BaseAWSService
    BaseAWSService <|-- EC2Service
    BaseAWSService <|-- LambdaService
    EC2Service --> AWSClientFactory
    LambdaService --> AWSClientFactory
```

## 4.3 Template Method - BaseAWSService

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Union
from dataclasses import dataclass

class BaseAWSService(ABC):
    """
    Classe base abstrata para todos os 253 serviÃ§os AWS.
    
    Implementa o padrÃ£o Template Method definindo:
    - Interface comum para todos os serviÃ§os
    - MÃ©todos hook para personalizaÃ§Ã£o
    - Logging e mÃ©tricas padronizadas
    
    Cada serviÃ§o concreto DEVE implementar todos os mÃ©todos abstratos.
    """
    
    def __init__(self, client_factory: AWSClientFactory):
        """
        Inicializa o serviÃ§o com a factory de clientes AWS.
        
        Args:
            client_factory: Factory para obter clientes boto3
        """
        self._client_factory = client_factory
        self.logger = setup_logger(self.__class__.__name__)
        self._metrics = MetricsCollector(self.__class__.__name__)
    
    @property
    def client_factory(self) -> AWSClientFactory:
        """Getter para client_factory (compatibilidade)."""
        return self._client_factory
    
    # =========================================================================
    # MÃ‰TODOS ABSTRATOS - DEVEM SER IMPLEMENTADOS POR CADA SERVIÃ‡O
    # =========================================================================
    
    @abstractmethod
    def health_check(self) -> Dict[str, Any]:
        """
        Verifica se o serviÃ§o AWS estÃ¡ acessÃ­vel e funcionando.
        
        Returns:
            Dict com:
            - status: 'healthy' | 'unhealthy' | 'degraded'
            - service: nome do serviÃ§o
            - latency_ms: tempo de resposta em ms
            - error: mensagem de erro (se unhealthy)
            
        Example:
            {'status': 'healthy', 'service': 'ec2', 'latency_ms': 45}
        """
        pass
    
    @abstractmethod
    def analyze_usage(self) -> Dict[str, Any]:
        """
        Analisa padrÃµes de uso e consumo do serviÃ§o.
        
        Returns:
            Dict com mÃ©tricas de uso especÃ­ficas do serviÃ§o.
            Cada serviÃ§o define suas prÃ³prias mÃ©tricas relevantes.
            
        Example (EC2):
            {
                'total_instances': 50,
                'running': 30,
                'stopped': 20,
                'by_type': {'t3.micro': 20, 'm5.large': 10},
                'underutilized': ['i-abc123', 'i-def456'],
                'overutilized': ['i-ghi789']
            }
        """
        pass
    
    @abstractmethod
    def get_recommendations(self) -> List[Dict[str, Any]]:
        """
        Retorna recomendaÃ§Ãµes de otimizaÃ§Ã£o de custos.
        
        Returns:
            Lista de recomendaÃ§Ãµes, cada uma com:
            - id: identificador Ãºnico
            - type: tipo de recomendaÃ§Ã£o
            - resource_id: recurso afetado
            - title: tÃ­tulo curto
            - description: descriÃ§Ã£o detalhada
            - estimated_savings: economia estimada em USD/mÃªs
            - effort: 'low' | 'medium' | 'high'
            - risk: 'low' | 'medium' | 'high'
            
        Example:
            [{
                'id': 'rec-001',
                'type': 'rightsizing',
                'resource_id': 'i-abc123',
                'title': 'Reduzir instÃ¢ncia subutilizada',
                'description': 'InstÃ¢ncia com CPU mÃ©dia de 5%...',
                'estimated_savings': 50.00,
                'effort': 'low',
                'risk': 'low'
            }]
        """
        pass
    
    @abstractmethod
    def get_resources(self) -> Union[List[Dict], Dict[str, Any]]:
        """
        Lista todos os recursos do serviÃ§o na conta/regiÃ£o.
        
        Returns:
            Lista de recursos ou Dict com recursos categorizados.
            Formato depende do serviÃ§o especÃ­fico.
        """
        pass
    
    @abstractmethod
    def get_metrics(self) -> Dict[str, Any]:
        """
        ObtÃ©m mÃ©tricas de performance e custo do CloudWatch.
        
        Returns:
            Dict com mÃ©tricas coletadas do CloudWatch.
        """
        pass
    
    # =========================================================================
    # MÃ‰TODOS TEMPLATE - COMPORTAMENTO COMUM
    # =========================================================================
    
    def execute_full_analysis(self) -> Dict[str, Any]:
        """
        Template method: executa anÃ¡lise completa do serviÃ§o.
        
        Ordem de execuÃ§Ã£o:
        1. health_check() - Verifica disponibilidade
        2. get_resources() - Lista recursos
        3. analyze_usage() - Analisa uso
        4. get_metrics() - Coleta mÃ©tricas
        5. get_recommendations() - Gera recomendaÃ§Ãµes
        
        Returns:
            Dict consolidado com todos os resultados
        """
        result = {
            'service': self.__class__.__name__,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        # 1. Health check
        health = self.health_check()
        result['health'] = health
        
        if health.get('status') != 'healthy':
            result['status'] = 'unhealthy'
            return result
        
        # 2. Coletar recursos
        result['resources'] = self.get_resources()
        
        # 3. Analisar uso
        result['usage'] = self.analyze_usage()
        
        # 4. Coletar mÃ©tricas
        result['metrics'] = self.get_metrics()
        
        # 5. Gerar recomendaÃ§Ãµes
        result['recommendations'] = self.get_recommendations()
        
        result['status'] = 'completed'
        return result
```

## 4.4 Circuit Breaker Pattern

```mermaid
stateDiagram-v2
    [*] --> CLOSED: InicializaÃ§Ã£o
    
    CLOSED --> CLOSED: Sucesso
    CLOSED --> CLOSED: Falha (count < threshold)
    CLOSED --> OPEN: Falha (count >= threshold)
    
    OPEN --> OPEN: Chamadas rejeitadas imediatamente
    OPEN --> HALF_OPEN: Timeout de recuperaÃ§Ã£o expirado
    
    HALF_OPEN --> CLOSED: Chamada de teste bem sucedida
    HALF_OPEN --> OPEN: Chamada de teste falhou
    
    note right of CLOSED
        Estado normal de operaÃ§Ã£o.
        Todas as chamadas passam.
        Contador de falhas ativo.
        Reset do contador apÃ³s sucesso.
    end note
    
    note right of OPEN
        Circuito aberto por falhas excessivas.
        Chamadas rejeitadas imediatamente.
        NÃ£o sobrecarrega serviÃ§o com problemas.
        Timer de recuperaÃ§Ã£o ativo.
    end note
    
    note right of HALF_OPEN
        Teste de recuperaÃ§Ã£o.
        Permite chamadas limitadas.
        Sucesso fecha o circuito.
        Falha reabre o circuito.
    end note
```

```python
from enum import Enum
from dataclasses import dataclass
from typing import Callable, Any
import time
import threading

class CircuitState(Enum):
    """Estados do Circuit Breaker."""
    CLOSED = "closed"      # Normal - chamadas permitidas
    OPEN = "open"          # Falhas - chamadas bloqueadas
    HALF_OPEN = "half_open"  # Teste - chamadas limitadas

@dataclass
class CircuitBreakerConfig:
    """ConfiguraÃ§Ã£o do Circuit Breaker."""
    failure_threshold: int = 5        # Falhas para abrir
    recovery_timeout: float = 30.0    # Segundos para tentar recuperar
    half_open_max_calls: int = 3      # Chamadas de teste
    success_threshold: int = 2        # Sucessos para fechar

class CircuitBreaker:
    """
    ImplementaÃ§Ã£o do padrÃ£o Circuit Breaker.
    
    Previne chamadas a serviÃ§os com falhas recorrentes,
    permitindo recuperaÃ§Ã£o gradual.
    """
    
    def __init__(self, name: str, config: CircuitBreakerConfig = None):
        self.name = name
        self.config = config or CircuitBreakerConfig()
        self._state = CircuitState.CLOSED
        self._failure_count = 0
        self._success_count = 0
        self._last_failure_time = None
        self._half_open_calls = 0
        self._lock = threading.Lock()
    
    @property
    def state(self) -> CircuitState:
        """Retorna estado atual, verificando timeout de recuperaÃ§Ã£o."""
        with self._lock:
            if self._state == CircuitState.OPEN:
                if self._should_attempt_recovery():
                    self._state = CircuitState.HALF_OPEN
                    self._half_open_calls = 0
            return self._state
    
    def _should_attempt_recovery(self) -> bool:
        """Verifica se timeout de recuperaÃ§Ã£o expirou."""
        if self._last_failure_time is None:
            return False
        elapsed = time.time() - self._last_failure_time
        return elapsed >= self.config.recovery_timeout
    
    def can_execute(self) -> bool:
        """Verifica se chamada Ã© permitida."""
        state = self.state
        if state == CircuitState.CLOSED:
            return True
        elif state == CircuitState.OPEN:
            return False
        else:  # HALF_OPEN
            with self._lock:
                if self._half_open_calls < self.config.half_open_max_calls:
                    self._half_open_calls += 1
                    return True
                return False
    
    def record_success(self):
        """Registra chamada bem sucedida."""
        with self._lock:
            if self._state == CircuitState.HALF_OPEN:
                self._success_count += 1
                if self._success_count >= self.config.success_threshold:
                    self._state = CircuitState.CLOSED
                    self._reset_counters()
            else:
                self._failure_count = 0  # Reset falhas apÃ³s sucesso
    
    def record_failure(self):
        """Registra falha."""
        with self._lock:
            self._failure_count += 1
            self._last_failure_time = time.time()
            
            if self._state == CircuitState.HALF_OPEN:
                # Falha em half-open reabre o circuito
                self._state = CircuitState.OPEN
                self._half_open_calls = 0
            elif self._failure_count >= self.config.failure_threshold:
                # Threshold atingido - abrir circuito
                self._state = CircuitState.OPEN
    
    def _reset_counters(self):
        """Reset contadores internos."""
        self._failure_count = 0
        self._success_count = 0
        self._half_open_calls = 0
        self._last_failure_time = None
    
    def execute(self, func: Callable, *args, **kwargs) -> Any:
        """
        Executa funÃ§Ã£o protegida pelo circuit breaker.
        
        Raises:
            CircuitBreakerOpenError: Se circuito estiver aberto
        """
        if not self.can_execute():
            raise CircuitBreakerOpenError(
                f"Circuit breaker '{self.name}' is OPEN"
            )
        
        try:
            result = func(*args, **kwargs)
            self.record_success()
            return result
        except Exception as e:
            self.record_failure()
            raise


class CircuitBreakerOpenError(Exception):
    """ExceÃ§Ã£o quando circuit breaker estÃ¡ aberto."""
    pass
```

## 4.5 Retry com Exponential Backoff

```python
import random
import time
from typing import Callable, Tuple, Type, Optional
from dataclasses import dataclass, field
from functools import wraps

@dataclass
class RetryPolicy:
    """
    PolÃ­tica de retry configurÃ¡vel.
    
    Implementa exponential backoff com jitter opcional
    para evitar thundering herd problem.
    """
    max_attempts: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    exponential_base: float = 2.0
    jitter: bool = True
    retryable_exceptions: Tuple[Type[Exception], ...] = field(
        default_factory=lambda: (
            ConnectionError,
            TimeoutError,
            OSError,
        )
    )
    
    def calculate_delay(self, attempt: int) -> float:
        """
        Calcula delay para tentativa N.
        
        FÃ³rmula: delay = min(base * (exp ^ attempt), max)
        Com jitter: delay *= random(0.5, 1.5)
        
        Args:
            attempt: NÃºmero da tentativa (0-indexed)
            
        Returns:
            Delay em segundos
        """
        delay = min(
            self.base_delay * (self.exponential_base ** attempt),
            self.max_delay
        )
        if self.jitter:
            delay *= random.uniform(0.5, 1.5)
        return delay
    
    def should_retry(self, exception: Exception, attempt: int) -> bool:
        """
        Determina se deve fazer retry.
        
        Args:
            exception: ExceÃ§Ã£o capturada
            attempt: NÃºmero da tentativa atual
            
        Returns:
            True se deve retry, False caso contrÃ¡rio
        """
        if attempt >= self.max_attempts:
            return False
        
        # Verificar se Ã© exceÃ§Ã£o retryable
        if isinstance(exception, self.retryable_exceptions):
            return True
        
        # Verificar erros AWS especÃ­ficos
        error_code = getattr(exception, 'response', {}).get('Error', {}).get('Code', '')
        retryable_codes = [
            'Throttling',
            'ThrottlingException',
            'RequestLimitExceeded',
            'ProvisionedThroughputExceededException',
            'ServiceUnavailable',
            'InternalError',
            'InternalServiceError'
        ]
        return error_code in retryable_codes


@dataclass
class RetryMetrics:
    """MÃ©tricas de retry para observabilidade."""
    total_attempts: int = 0
    successful_attempts: int = 0
    failed_attempts: int = 0
    total_retry_delay: float = 0.0
    last_error: Optional[str] = None
    
    def record_attempt(self, success: bool, delay: float = 0.0, error: str = None):
        """Registra tentativa."""
        self.total_attempts += 1
        if success:
            self.successful_attempts += 1
        else:
            self.failed_attempts += 1
            self.total_retry_delay += delay
            self.last_error = error


class RetryHandler:
    """
    Handler para execuÃ§Ã£o com retry.
    
    Uso:
        handler = RetryHandler(RetryPolicy())
        result = handler.execute(my_function, arg1, arg2)
    """
    
    def __init__(self, policy: RetryPolicy = None, on_retry: Callable = None):
        self.policy = policy or RetryPolicy()
        self.on_retry = on_retry  # Callback opcional
        self.metrics = RetryMetrics()
    
    def execute(self, func: Callable, *args, **kwargs):
        """
        Executa funÃ§Ã£o com retry automÃ¡tico.
        
        Args:
            func: FunÃ§Ã£o a executar
            *args, **kwargs: Argumentos da funÃ§Ã£o
            
        Returns:
            Resultado da funÃ§Ã£o
            
        Raises:
            Ãšltima exceÃ§Ã£o se todos os retries falharem
        """
        last_exception = None
        
        for attempt in range(self.policy.max_attempts):
            try:
                result = func(*args, **kwargs)
                self.metrics.record_attempt(success=True)
                return result
                
            except Exception as e:
                last_exception = e
                
                if not self.policy.should_retry(e, attempt + 1):
                    self.metrics.record_attempt(success=False, error=str(e))
                    raise
                
                # Calcular delay e aguardar
                delay = self.policy.calculate_delay(attempt)
                self.metrics.record_attempt(success=False, delay=delay, error=str(e))
                
                # Callback de retry (logging, mÃ©tricas, etc.)
                if self.on_retry:
                    self.on_retry(attempt + 1, delay, e)
                
                time.sleep(delay)
        
        # Todas as tentativas falharam
        raise last_exception
    
    @staticmethod
    def with_retry(
        max_attempts: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 60.0
    ):
        """
        Decorator para adicionar retry a funÃ§Ãµes.
        
        Uso:
            @RetryHandler.with_retry(max_attempts=5)
            def my_function():
                ...
        """
        def decorator(func: Callable):
            @wraps(func)
            def wrapper(*args, **kwargs):
                policy = RetryPolicy(
                    max_attempts=max_attempts,
                    base_delay=base_delay,
                    max_delay=max_delay
                )
                handler = RetryHandler(policy)
                return handler.execute(func, *args, **kwargs)
            return wrapper
        return decorator
```

---

# 5. Estrutura de Camadas

## 5.1 Diagrama de Camadas (Onion Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     CAMADA DE APRESENTAÃ‡ÃƒO                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   Lambda    â”‚  â”‚    API      â”‚  â”‚    CLI      â”‚  â”‚  Dashboard  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   Handler   â”‚  â”‚   Gateway   â”‚  â”‚   Runner    â”‚  â”‚    HTML     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                      â”‚
â”‚                                      â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     CAMADA DE APLICAÃ‡ÃƒO                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Resilient  â”‚  â”‚    State    â”‚  â”‚   Retry     â”‚  â”‚  Forecastingâ”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Executor   â”‚  â”‚   Manager   â”‚  â”‚   Handler   â”‚  â”‚   Engine    â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                      â”‚
â”‚                                      â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      CAMADA DE DOMÃNIO                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   Service   â”‚  â”‚    Base     â”‚  â”‚   FinOps    â”‚  â”‚   Domain    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   Factory   â”‚  â”‚ AWSService  â”‚  â”‚   Models    â”‚  â”‚   Events    â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                                       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚                    253 SERVIÃ‡OS AWS                             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  EC2 â”‚ Lambda â”‚ S3 â”‚ RDS â”‚ DynamoDB â”‚ EKS â”‚ SageMaker â”‚ ...    â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                      â”‚
â”‚                                      â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   CAMADA DE INFRAESTRUTURA                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚    AWS      â”‚  â”‚     S3      â”‚  â”‚   boto3     â”‚  â”‚   Logger    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ClientFactoryâ”‚  â”‚StateManager â”‚  â”‚   Clients   â”‚  â”‚   Config    â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.2 Estrutura de DiretÃ³rios Detalhada

```
finops-aws/
â”‚
â”œâ”€â”€ src/finops_aws/                    # CÃ³digo-fonte principal
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py                    # Exports do mÃ³dulo
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                          # NÃºcleo da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ factories.py               # ServiceFactory + AWSClientFactory
â”‚   â”‚   â”œâ”€â”€ s3_state_manager.py        # Gerenciamento de estado (S3)
â”‚   â”‚   â”œâ”€â”€ state_manager.py           # State manager local (dev)
â”‚   â”‚   â”œâ”€â”€ resilient_executor.py      # Executor com resiliÃªncia
â”‚   â”‚   â”œâ”€â”€ retry_handler.py           # PolÃ­ticas de retry
â”‚   â”‚   â”œâ”€â”€ cleanup_manager.py         # Limpeza de recursos
â”‚   â”‚   â”œâ”€â”€ multi_account_handler.py   # Suporte multi-conta
â”‚   â”‚   â”œâ”€â”€ forecasting_engine.py      # PrevisÃµes ML
â”‚   â”‚   â””â”€â”€ api_gateway_handler.py     # REST API
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                        # Modelos de domÃ­nio
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ finops_models.py           # Dataclasses principais
â”‚   â”‚   â”œâ”€â”€ recommendations.py         # Tipos de recomendaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ metrics.py                 # Modelos de mÃ©tricas
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                      # 253 serviÃ§os AWS
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_service.py            # BaseAWSService (abstrata)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ # COMPUTE & SERVERLESS (25 serviÃ§os)
â”‚   â”‚   â”œâ”€â”€ ec2_service.py
â”‚   â”‚   â”œâ”€â”€ ec2_finops_service.py
â”‚   â”‚   â”œâ”€â”€ lambda_service.py
â”‚   â”‚   â”œâ”€â”€ lambda_finops_service.py
â”‚   â”‚   â”œâ”€â”€ lambda_edge_service.py
â”‚   â”‚   â”œâ”€â”€ batch_service.py
â”‚   â”‚   â”œâ”€â”€ lightsail_service.py
â”‚   â”‚   â”œâ”€â”€ app_runner_service.py
â”‚   â”‚   â”œâ”€â”€ elastic_beanstalk_service.py
â”‚   â”‚   â”œâ”€â”€ sam_service.py
â”‚   â”‚   â”œâ”€â”€ outposts_service.py
â”‚   â”‚   â”œâ”€â”€ local_zones_service.py
â”‚   â”‚   â”œâ”€â”€ wavelength_service.py
â”‚   â”‚   â”œâ”€â”€ private_5g_service.py
â”‚   â”‚   â”œâ”€â”€ auto_scaling_service.py
â”‚   â”‚   â”œâ”€â”€ ecs_container_service.py
â”‚   â”‚   â”œâ”€â”€ eks_service.py
â”‚   â”‚   â”œâ”€â”€ ecr_service.py
â”‚   â”‚   â”œâ”€â”€ fargate_service.py
â”‚   â”‚   â”œâ”€â”€ step_functions_service.py
â”‚   â”‚   â”œâ”€â”€ eventbridge_service.py
â”‚   â”‚   â”œâ”€â”€ amplify_service.py
â”‚   â”‚   â”œâ”€â”€ proton_service.py
â”‚   â”‚   â”œâ”€â”€ ec2_spot_service.py
â”‚   â”‚   â”œâ”€â”€ ec2_reserved_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ # STORAGE (15 serviÃ§os)
â”‚   â”‚   â”œâ”€â”€ s3_service.py
â”‚   â”‚   â”œâ”€â”€ ebs_service.py
â”‚   â”‚   â”œâ”€â”€ efs_service.py
â”‚   â”‚   â”œâ”€â”€ fsx_service.py
â”‚   â”‚   â”œâ”€â”€ storage_gateway_service.py
â”‚   â”‚   â”œâ”€â”€ backup_service.py
â”‚   â”‚   â”œâ”€â”€ datasync_service.py
â”‚   â”‚   â”œâ”€â”€ snow_service.py
â”‚   â”‚   â”œâ”€â”€ transfer_family_service.py
â”‚   â”‚   â”œâ”€â”€ s3_glacier_service.py
â”‚   â”‚   â”œâ”€â”€ s3_intelligent_tiering_service.py
â”‚   â”‚   â”œâ”€â”€ ebs_snapshots_service.py
â”‚   â”‚   â”œâ”€â”€ file_cache_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ # DATABASE (25 serviÃ§os)
â”‚   â”‚   â”œâ”€â”€ rds_service.py
â”‚   â”‚   â”œâ”€â”€ aurora_service.py
â”‚   â”‚   â”œâ”€â”€ aurora_serverless_service.py
â”‚   â”‚   â”œâ”€â”€ dynamodb_finops_service.py
â”‚   â”‚   â”œâ”€â”€ dynamodb_global_service.py
â”‚   â”‚   â”œâ”€â”€ dynamodb_streams_service.py
â”‚   â”‚   â”œâ”€â”€ elasticache_service.py
â”‚   â”‚   â”œâ”€â”€ elasticache_global_service.py
â”‚   â”‚   â”œâ”€â”€ elasticache_serverless_service.py
â”‚   â”‚   â”œâ”€â”€ memorydb_service.py
â”‚   â”‚   â”œâ”€â”€ redshift_service.py
â”‚   â”‚   â”œâ”€â”€ redshift_serverless_service.py
â”‚   â”‚   â”œâ”€â”€ documentdb_service.py
â”‚   â”‚   â”œâ”€â”€ neptune_service.py
â”‚   â”‚   â”œâ”€â”€ keyspaces_service.py
â”‚   â”‚   â”œâ”€â”€ timestream_service.py
â”‚   â”‚   â”œâ”€â”€ qldb_service.py
â”‚   â”‚   â”œâ”€â”€ opensearch_service.py
â”‚   â”‚   â”œâ”€â”€ opensearch_serverless_service.py
â”‚   â”‚   â”œâ”€â”€ rds_proxy_service.py
â”‚   â”‚   â”œâ”€â”€ dms_service.py
â”‚   â”‚   â”œâ”€â”€ dms_migration_service.py
â”‚   â”‚   â”œâ”€â”€ schema_conversion_service.py
â”‚   â”‚   â”œâ”€â”€ rds_finops_service.py
â”‚   â”‚   â”œâ”€â”€ database_insights_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ # ... mais 188 serviÃ§os em outras categorias
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ __all__.py                 # Exports de todos os serviÃ§os
â”‚   â”‚
â”‚   â””â”€â”€ utils/                         # UtilitÃ¡rios
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py                  # ConfiguraÃ§Ã£o de logging
â”‚       â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes
â”‚       â””â”€â”€ helpers.py                 # FunÃ§Ãµes auxiliares
â”‚
â”œâ”€â”€ tests/                             # Suite de testes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                    # Fixtures pytest
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/                          # Testes unitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ test_factories.py          # Testes ServiceFactory
â”‚   â”‚   â”œâ”€â”€ test_state_manager.py      # Testes StateManager
â”‚   â”‚   â”œâ”€â”€ test_resilient_executor.py # Testes ResilientExecutor
â”‚   â”‚   â”œâ”€â”€ test_retry_handler.py      # Testes RetryHandler
â”‚   â”‚   â”œâ”€â”€ test_phase1_services.py    # Testes serviÃ§os fase 1
â”‚   â”‚   â”œâ”€â”€ test_phase2_services.py    # Testes serviÃ§os fase 2
â”‚   â”‚   â”œâ”€â”€ ... (14 fases de testes)
â”‚   â”‚   â””â”€â”€ test_qa_comprehensive.py   # Testes QA 78 cenÃ¡rios
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                   # Testes de integraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ test_integration_aws.py
â”‚   â”‚   â””â”€â”€ test_integration_s3.py
â”‚   â”‚
â”‚   â””â”€â”€ e2e/                           # Testes end-to-end
â”‚       â””â”€â”€ test_full_execution.py
â”‚
â”œâ”€â”€ infrastructure/                    # Infraestrutura como cÃ³digo
â”‚   â””â”€â”€ terraform/                     # Terraform (3,006 LOC)
â”‚       â”œâ”€â”€ main.tf                    # ConfiguraÃ§Ã£o principal
â”‚       â”œâ”€â”€ lambda.tf                  # FunÃ§Ãµes Lambda
â”‚       â”œâ”€â”€ step_functions.tf          # State Machine
â”‚       â”œâ”€â”€ iam.tf                     # Roles e policies
â”‚       â”œâ”€â”€ s3.tf                      # Buckets S3
â”‚       â”œâ”€â”€ eventbridge.tf             # Schedules
â”‚       â”œâ”€â”€ security.tf                # KMS, WAF
â”‚       â”œâ”€â”€ monitoring.tf              # CloudWatch
â”‚       â”œâ”€â”€ variables.tf               # VariÃ¡veis
â”‚       â”œâ”€â”€ outputs.tf                 # Outputs
â”‚       â””â”€â”€ README_TERRAFORM.md        # DocumentaÃ§Ã£o
â”‚
â”œâ”€â”€ docs/                              # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ HEAD_FIRST_FINOPS.md           # Guia executivo
â”‚   â”œâ”€â”€ TECHNICAL_GUIDE.md             # Este documento
â”‚   â”œâ”€â”€ FUNCTIONAL_GUIDE.md            # Guia funcional
â”‚   â”œâ”€â”€ USER_MANUAL.md                 # Manual do usuÃ¡rio
â”‚   â”œâ”€â”€ APPENDIX_SERVICES.md           # CatÃ¡logo de serviÃ§os
â”‚   â”œâ”€â”€ QA_REPORT.md                   # RelatÃ³rio de qualidade
â”‚   â”œâ”€â”€ PRODUCTION_READINESS_REPORT.md # ProntidÃ£o para produÃ§Ã£o
â”‚   â””â”€â”€ QA_GAP_ANALYSIS.md             # AnÃ¡lise de lacunas
â”‚
â”œâ”€â”€ example_events/                    # Eventos de exemplo
â”‚   â”œâ”€â”€ scheduled_event.json
â”‚   â”œâ”€â”€ api_gateway_event.json
â”‚   â””â”€â”€ sns_event.json
â”‚
â”œâ”€â”€ scripts/                           # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ quick_test.py
â”‚   â”œâ”€â”€ test_all_services.py
â”‚   â””â”€â”€ deploy_and_test.sh
â”‚
â”œâ”€â”€ run_local_demo.py                  # Demo local
â”œâ”€â”€ run_with_aws.py                    # ExecuÃ§Ã£o com AWS real
â”œâ”€â”€ requirements.txt                   # DependÃªncias Python
â”œâ”€â”€ pyproject.toml                     # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ replit.md                          # DocumentaÃ§Ã£o Replit
â””â”€â”€ README.md                          # README principal
```

## 5.3 DependÃªncias entre Camadas

```mermaid
graph TD
    subgraph "Camada de ApresentaÃ§Ã£o"
        A[Lambda Handler]
        B[CLI Runner]
        C[API Gateway Handler]
        D[Dashboard HTML]
    end
    
    subgraph "Camada de AplicaÃ§Ã£o"
        E[ResilientExecutor]
        F[S3StateManager]
        G[RetryHandler]
        H[ForecastingEngine]
        I[MultiAccountHandler]
    end
    
    subgraph "Camada de DomÃ­nio"
        J[ServiceFactory]
        K[BaseAWSService]
        L[FinOps Models]
        M[253 Services]
    end
    
    subgraph "Camada de Infraestrutura"
        N[AWSClientFactory]
        O[S3 Client]
        P[boto3]
        Q[Logger]
    end
    
    A --> E
    B --> E
    C --> E
    D --> C
    
    E --> F
    E --> G
    E --> J
    
    F --> O
    G --> Q
    
    J --> K
    J --> N
    K --> L
    K --> N
    M --> K
    
    N --> P
    O --> P
    
    style A fill:#e1f5fe
    style B fill:#e1f5fe
    style C fill:#e1f5fe
    style D fill:#e1f5fe
    style E fill:#fff3e0
    style F fill:#fff3e0
    style G fill:#fff3e0
    style J fill:#e8f5e9
    style K fill:#e8f5e9
    style L fill:#e8f5e9
    style M fill:#e8f5e9
    style N fill:#fce4ec
    style O fill:#fce4ec
    style P fill:#fce4ec
```

---

# 6. Componentes Core Detalhados

## 6.1 AWSClientFactory

O `AWSClientFactory` Ã© responsÃ¡vel pela criaÃ§Ã£o e cache de clientes boto3:

```python
from typing import Any, Dict, Optional
from enum import Enum
import boto3
from botocore.config import Config

class AWSServiceType(Enum):
    """
    EnumeraÃ§Ã£o de todos os 253 tipos de serviÃ§os AWS.
    
    Organizado por categoria para facilitar manutenÃ§Ã£o.
    Cada valor corresponde ao nome do serviÃ§o no boto3.
    """
    
    # COMPUTE & SERVERLESS
    EC2 = 'ec2'
    LAMBDA = 'lambda'
    BATCH = 'batch'
    LIGHTSAIL = 'lightsail'
    APPRUNNER = 'apprunner'
    ELASTICBEANSTALK = 'elasticbeanstalk'
    ECS = 'ecs'
    EKS = 'eks'
    ECR = 'ecr'
    STEPFUNCTIONS = 'stepfunctions'
    EVENTBRIDGE = 'events'
    
    # STORAGE
    S3 = 's3'
    EBS = 'ec2'  # EBS usa cliente EC2
    EFS = 'efs'
    FSX = 'fsx'
    GLACIER = 'glacier'
    STORAGE_GATEWAY = 'storagegateway'
    BACKUP = 'backup'
    
    # DATABASE
    RDS = 'rds'
    DYNAMODB = 'dynamodb'
    ELASTICACHE = 'elasticache'
    REDSHIFT = 'redshift'
    DOCUMENTDB = 'docdb'
    NEPTUNE = 'neptune'
    KEYSPACES = 'keyspaces'
    TIMESTREAM_WRITE = 'timestream-write'
    QLDB = 'qldb'
    OPENSEARCH = 'opensearch'
    
    # NETWORKING
    VPC = 'ec2'  # VPC usa cliente EC2
    ELB = 'elbv2'
    CLOUDFRONT = 'cloudfront'
    ROUTE53 = 'route53'
    APIGATEWAY = 'apigateway'
    DIRECTCONNECT = 'directconnect'
    TRANSIT_GATEWAY = 'ec2'
    
    # SECURITY
    IAM = 'iam'
    KMS = 'kms'
    SECRETS_MANAGER = 'secretsmanager'
    ACM = 'acm'
    WAF = 'wafv2'
    GUARDDUTY = 'guardduty'
    SECURITY_HUB = 'securityhub'
    MACIE = 'macie2'
    INSPECTOR = 'inspector2'
    
    # MONITORING
    CLOUDWATCH = 'cloudwatch'
    CLOUDWATCH_LOGS = 'logs'
    XRAY = 'xray'
    
    # COST MANAGEMENT
    COST_EXPLORER = 'ce'
    BUDGETS = 'budgets'
    
    # AI/ML
    SAGEMAKER = 'sagemaker'
    BEDROCK = 'bedrock'
    COMPREHEND = 'comprehend'
    REKOGNITION = 'rekognition'
    TEXTRACT = 'textract'
    TRANSLATE = 'translate'
    POLLY = 'polly'
    TRANSCRIBE = 'transcribe'
    LEX = 'lex-models'
    PERSONALIZE = 'personalize'
    FORECAST = 'forecast'
    
    # ANALYTICS
    ATHENA = 'athena'
    GLUE = 'glue'
    EMR = 'emr'
    KINESIS = 'kinesis'
    QUICKSIGHT = 'quicksight'
    LAKE_FORMATION = 'lakeformation'
    MSK = 'kafka'
    
    # DEVELOPER TOOLS
    CODECOMMIT = 'codecommit'
    CODEBUILD = 'codebuild'
    CODEPIPELINE = 'codepipeline'
    CODEDEPLOY = 'codedeploy'
    
    # MANAGEMENT
    CLOUDFORMATION = 'cloudformation'
    CLOUDTRAIL = 'cloudtrail'
    CONFIG = 'config'
    ORGANIZATIONS = 'organizations'
    SSM = 'ssm'
    
    # ... mais 150+ serviÃ§os


class AWSClientFactory:
    """
    Factory para criaÃ§Ã£o de clientes AWS boto3.
    
    CaracterÃ­sticas:
    - Cache de clientes para reutilizaÃ§Ã£o
    - ConfiguraÃ§Ã£o de timeouts e retries
    - Suporte a mÃºltiplas regiÃµes
    - InjeÃ§Ã£o de mocks para testes
    
    Exemplo de uso:
        factory = AWSClientFactory(region='us-east-1')
        ec2 = factory.get_client(AWSServiceType.EC2)
        s3 = factory.get_client(AWSServiceType.S3)
    """
    
    # ConfiguraÃ§Ã£o padrÃ£o de retry do boto3
    DEFAULT_CONFIG = Config(
        retries={
            'max_attempts': 3,
            'mode': 'adaptive'  # Adapta baseado em throttling
        },
        connect_timeout=5,
        read_timeout=30
    )
    
    def __init__(
        self,
        region: str = 'us-east-1',
        config: Config = None,
        session: boto3.Session = None
    ):
        """
        Inicializa a factory de clientes AWS.
        
        Args:
            region: RegiÃ£o AWS padrÃ£o
            config: ConfiguraÃ§Ã£o boto3 customizada
            session: Session boto3 customizada (para testes)
        """
        self.region = region
        self._config = config or self.DEFAULT_CONFIG
        self._session = session or boto3.Session()
        self._clients: Dict[str, Any] = {}
        self._mocks: Dict[str, Any] = {}
    
    def get_client(self, service_type: AWSServiceType) -> Any:
        """
        ObtÃ©m cliente boto3 para o serviÃ§o especificado.
        
        Utiliza cache para evitar criaÃ§Ã£o repetida.
        Retorna mock se registrado para testes.
        
        Args:
            service_type: Tipo de serviÃ§o AWS
            
        Returns:
            Cliente boto3 para o serviÃ§o
        """
        service_name = service_type.value
        
        # Verificar se hÃ¡ mock registrado
        if service_name in self._mocks:
            return self._mocks[service_name]
        
        # Verificar cache
        if service_name not in self._clients:
            self._clients[service_name] = self._session.client(
                service_name,
                region_name=self.region,
                config=self._config
            )
        
        return self._clients[service_name]
    
    def get_resource(self, service_type: AWSServiceType) -> Any:
        """
        ObtÃ©m resource boto3 para o serviÃ§o.
        
        Ãštil para S3, DynamoDB e outros que suportam resources.
        """
        return self._session.resource(
            service_type.value,
            region_name=self.region,
            config=self._config
        )
    
    def register_mock(self, service_type: AWSServiceType, mock: Any):
        """
        Registra mock para testes.
        
        Args:
            service_type: ServiÃ§o a mockar
            mock: Objeto mock
        """
        self._mocks[service_type.value] = mock
    
    def clear_mocks(self):
        """Remove todos os mocks registrados."""
        self._mocks.clear()
    
    def clear_cache(self):
        """Limpa cache de clientes."""
        self._clients.clear()
```

## 6.2 ServiceFactory

O `ServiceFactory` implementa o padrÃ£o Factory para criar e cachear serviÃ§os:

```python
from typing import Dict, Optional, Type
import threading

class ServiceFactory:
    """
    Factory para criaÃ§Ã£o de serviÃ§os AWS FinOps.
    
    Implementa:
    - Singleton pattern (Ãºnica instÃ¢ncia)
    - Lazy loading (serviÃ§os criados sob demanda)
    - Cache de serviÃ§os (evita recriaÃ§Ã£o)
    - InjeÃ§Ã£o de dependÃªncias (client_factory)
    - Suporte a mocks para testes
    
    Uso:
        factory = ServiceFactory()  # Singleton
        ec2 = factory.get_ec2_service()
        lambda_svc = factory.get_lambda_service()
        all_services = factory.get_all_services()
    """
    
    _instance: Optional['ServiceFactory'] = None
    _lock = threading.Lock()
    
    def __new__(cls, *args, **kwargs):
        """Singleton pattern - garante Ãºnica instÃ¢ncia."""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, client_factory: AWSClientFactory = None):
        """
        Inicializa a factory com client factory opcional.
        
        Args:
            client_factory: Factory de clientes boto3.
                           Se nÃ£o fornecido, cria um novo.
        """
        # Evitar reinicializaÃ§Ã£o do singleton
        if hasattr(self, '_initialized') and self._initialized:
            return
        
        self.client_factory = client_factory or AWSClientFactory()
        self._services: Dict[str, BaseAWSService] = {}
        self._mocks: Dict[str, BaseAWSService] = {}
        self._initialized = True
    
    @classmethod
    def get_instance(cls, client_factory: AWSClientFactory = None) -> 'ServiceFactory':
        """ObtÃ©m instÃ¢ncia singleton."""
        if cls._instance is None:
            cls._instance = cls(client_factory)
        return cls._instance
    
    @classmethod
    def reset_instance(cls):
        """Reset singleton (para testes)."""
        with cls._lock:
            cls._instance = None
    
    # =========================================================================
    # GETTERS PARA CADA SERVIÃ‡O (253 mÃ©todos)
    # =========================================================================
    
    def get_ec2_service(self) -> 'EC2Service':
        """ObtÃ©m serviÃ§o EC2."""
        return self._get_or_create_service('ec2', EC2Service)
    
    def get_lambda_service(self) -> 'LambdaService':
        """ObtÃ©m serviÃ§o Lambda."""
        return self._get_or_create_service('lambda', LambdaService)
    
    def get_s3_service(self) -> 'S3Service':
        """ObtÃ©m serviÃ§o S3."""
        return self._get_or_create_service('s3', S3Service)
    
    def get_rds_service(self) -> 'RDSService':
        """ObtÃ©m serviÃ§o RDS."""
        return self._get_or_create_service('rds', RDSService)
    
    def get_dynamodb_service(self) -> 'DynamoDBFinOpsService':
        """ObtÃ©m serviÃ§o DynamoDB."""
        return self._get_or_create_service('dynamodb', DynamoDBFinOpsService)
    
    def get_eks_service(self) -> 'EKSService':
        """ObtÃ©m serviÃ§o EKS."""
        return self._get_or_create_service('eks', EKSService)
    
    def get_ecs_service(self) -> 'ECSContainerService':
        """ObtÃ©m serviÃ§o ECS."""
        return self._get_or_create_service('ecs', ECSContainerService)
    
    # ... 246 outros getters ...
    
    def get_all_services(self) -> Dict[str, BaseAWSService]:
        """
        Retorna dicionÃ¡rio com todos os 253 serviÃ§os.
        
        Returns:
            Dict[nome_serviÃ§o, instÃ¢ncia_serviÃ§o]
        """
        all_getters = [
            ('ec2', self.get_ec2_service),
            ('lambda', self.get_lambda_service),
            ('s3', self.get_s3_service),
            ('rds', self.get_rds_service),
            ('dynamodb', self.get_dynamodb_service),
            ('eks', self.get_eks_service),
            ('ecs', self.get_ecs_service),
            # ... 246 outros
        ]
        
        return {name: getter() for name, getter in all_getters}
    
    # =========================================================================
    # MÃ‰TODOS INTERNOS
    # =========================================================================
    
    def _get_or_create_service(
        self,
        name: str,
        service_class: Type[BaseAWSService]
    ) -> BaseAWSService:
        """
        ObtÃ©m serviÃ§o do cache ou cria novo.
        
        Args:
            name: Nome do serviÃ§o
            service_class: Classe do serviÃ§o
            
        Returns:
            InstÃ¢ncia do serviÃ§o (cached ou nova)
        """
        # Verificar mock primeiro
        if name in self._mocks:
            return self._mocks[name]
        
        # Verificar cache
        if name not in self._services:
            self._services[name] = service_class(self.client_factory)
        
        return self._services[name]
    
    def register_mock(self, name: str, mock: BaseAWSService):
        """Registra mock de serviÃ§o para testes."""
        self._mocks[name] = mock
    
    def clear_mocks(self):
        """Remove todos os mocks."""
        self._mocks.clear()
    
    def clear_cache(self):
        """Limpa cache de serviÃ§os."""
        self._services.clear()
```

---

# 7. Camada de ServiÃ§os AWS

## 7.1 Hierarquia de ServiÃ§os

```mermaid
graph TD
    A[BaseAWSService<br/>Classe Abstrata] --> B[EC2Service]
    A --> C[LambdaService]
    A --> D[S3Service]
    A --> E[RDSService]
    A --> F[DynamoDBFinOpsService]
    A --> G[EKSService]
    A --> H[VPCService]
    A --> I[IAMService]
    A --> J[CloudWatchService]
    A --> K[...243 outros]
    
    subgraph "Compute & Serverless"
        B
        C
        G
    end
    
    subgraph "Storage"
        D
    end
    
    subgraph "Database"
        E
        F
    end
    
    subgraph "Networking"
        H
    end
    
    subgraph "Security"
        I
    end
    
    subgraph "Observability"
        J
    end
```

## 7.2 Exemplo Detalhado: EC2Service

```python
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import statistics

@dataclass
class EC2Instance:
    """Representa uma instÃ¢ncia EC2."""
    instance_id: str
    instance_type: str
    state: str
    launch_time: datetime
    availability_zone: str
    vpc_id: Optional[str]
    subnet_id: Optional[str]
    private_ip: Optional[str]
    public_ip: Optional[str]
    tags: Dict[str, str] = field(default_factory=dict)
    platform: str = 'linux'
    
    @property
    def name(self) -> str:
        """ObtÃ©m nome da tag Name."""
        return self.tags.get('Name', self.instance_id)
    
    @property
    def is_running(self) -> bool:
        """Verifica se instÃ¢ncia estÃ¡ running."""
        return self.state == 'running'
    
    def to_dict(self) -> Dict:
        """Converte para dicionÃ¡rio."""
        return {
            'instance_id': self.instance_id,
            'instance_type': self.instance_type,
            'state': self.state,
            'name': self.name,
            'availability_zone': self.availability_zone,
            'vpc_id': self.vpc_id,
            'private_ip': self.private_ip,
            'public_ip': self.public_ip,
            'platform': self.platform
        }


class EC2Service(BaseAWSService):
    """
    ServiÃ§o de anÃ¡lise FinOps para Amazon EC2.
    
    Capacidades:
    - InventÃ¡rio completo de instÃ¢ncias
    - AnÃ¡lise de utilizaÃ§Ã£o (CPU, memÃ³ria, rede, disco)
    - DetecÃ§Ã£o de instÃ¢ncias ociosas
    - RecomendaÃ§Ãµes de rightsizing
    - AnÃ¡lise de Reserved Instances
    - Monitoramento de Spot Instances
    - AnÃ¡lise de custos por instÃ¢ncia
    
    MÃ©tricas CloudWatch analisadas:
    - CPUUtilization
    - NetworkIn / NetworkOut
    - DiskReadOps / DiskWriteOps
    - StatusCheckFailed
    """
    
    # Thresholds para anÃ¡lise
    CPU_UNDERUTILIZED_THRESHOLD = 10.0  # %
    CPU_OVERUTILIZED_THRESHOLD = 80.0   # %
    IDLE_DAYS_THRESHOLD = 7             # dias
    
    def __init__(self, client_factory: AWSClientFactory):
        super().__init__(client_factory)
        self._ec2 = client_factory.get_client(AWSServiceType.EC2)
        self._cloudwatch = client_factory.get_client(AWSServiceType.CLOUDWATCH)
        self._cost_explorer = client_factory.get_client(AWSServiceType.COST_EXPLORER)
    
    def health_check(self) -> Dict[str, Any]:
        """
        Verifica conectividade com EC2 API.
        
        Returns:
            Dict com status de saÃºde do serviÃ§o
        """
        start_time = datetime.utcnow()
        try:
            # Chamada mÃ­nima para verificar conectividade
            self._ec2.describe_instances(MaxResults=5)
            latency = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            return {
                'status': 'healthy',
                'service': 'ec2',
                'latency_ms': round(latency, 2),
                'timestamp': datetime.utcnow().isoformat()
            }
        except Exception as e:
            self.logger.error(f"EC2 health check failed: {e}")
            return {
                'status': 'unhealthy',
                'service': 'ec2',
                'error': str(e),
                'timestamp': datetime.utcnow().isoformat()
            }
    
    def get_resources(self) -> Dict[str, Any]:
        """
        Lista todas as instÃ¢ncias EC2.
        
        Returns:
            Dict com inventÃ¡rio de instÃ¢ncias
        """
        instances = self._get_all_instances()
        
        # Agrupar por estado
        by_state = {}
        for instance in instances:
            state = instance.state
            if state not in by_state:
                by_state[state] = []
            by_state[state].append(instance.to_dict())
        
        # Agrupar por tipo
        by_type = {}
        for instance in instances:
            itype = instance.instance_type
            if itype not in by_type:
                by_type[itype] = 0
            by_type[itype] += 1
        
        return {
            'total_instances': len(instances),
            'by_state': by_state,
            'by_type': by_type,
            'instances': [i.to_dict() for i in instances]
        }
    
    def analyze_usage(self) -> Dict[str, Any]:
        """
        Analisa utilizaÃ§Ã£o das instÃ¢ncias EC2.
        
        Coleta mÃ©tricas dos Ãºltimos 30 dias e identifica:
        - InstÃ¢ncias subutilizadas (CPU < 10%)
        - InstÃ¢ncias sobreutilizadas (CPU > 80%)
        - InstÃ¢ncias paradas hÃ¡ muito tempo
        
        Returns:
            Dict com anÃ¡lise de uso detalhada
        """
        instances = self._get_all_instances()
        
        analysis = {
            'timestamp': datetime.utcnow().isoformat(),
            'total_instances': len(instances),
            'running': 0,
            'stopped': 0,
            'underutilized': [],
            'overutilized': [],
            'idle_stopped': [],
            'metrics_summary': {}
        }
        
        for instance in instances:
            if instance.state == 'running':
                analysis['running'] += 1
                
                # Coletar mÃ©tricas
                metrics = self._get_instance_metrics(instance.instance_id)
                
                # Classificar por utilizaÃ§Ã£o
                cpu_avg = metrics.get('cpu_average', 50)
                
                if cpu_avg < self.CPU_UNDERUTILIZED_THRESHOLD:
                    analysis['underutilized'].append({
                        'instance_id': instance.instance_id,
                        'name': instance.name,
                        'instance_type': instance.instance_type,
                        'cpu_average': cpu_avg,
                        'recommendation': 'Consider downsizing or terminating'
                    })
                elif cpu_avg > self.CPU_OVERUTILIZED_THRESHOLD:
                    analysis['overutilized'].append({
                        'instance_id': instance.instance_id,
                        'name': instance.name,
                        'instance_type': instance.instance_type,
                        'cpu_average': cpu_avg,
                        'recommendation': 'Consider upsizing'
                    })
            
            elif instance.state == 'stopped':
                analysis['stopped'] += 1
                
                # Verificar hÃ¡ quanto tempo estÃ¡ parada
                days_stopped = (datetime.utcnow() - instance.launch_time.replace(tzinfo=None)).days
                if days_stopped > self.IDLE_DAYS_THRESHOLD:
                    analysis['idle_stopped'].append({
                        'instance_id': instance.instance_id,
                        'name': instance.name,
                        'days_stopped': days_stopped,
                        'recommendation': 'Consider terminating or creating AMI'
                    })
        
        # Calcular mÃ©tricas agregadas
        analysis['metrics_summary'] = {
            'underutilized_count': len(analysis['underutilized']),
            'overutilized_count': len(analysis['overutilized']),
            'idle_stopped_count': len(analysis['idle_stopped']),
            'utilization_rate': f"{(analysis['running']/max(1, len(instances)))*100:.1f}%"
        }
        
        return analysis
    
    def get_recommendations(self) -> List[Dict[str, Any]]:
        """
        Gera recomendaÃ§Ãµes de otimizaÃ§Ã£o para EC2.
        
        Tipos de recomendaÃ§Ãµes:
        1. Rightsizing down (CPU < 10%)
        2. Rightsizing up (CPU > 80%)
        3. Terminate idle (stopped > 7 dias)
        4. Reserved Instances (uso consistente)
        5. Spot Instances (workloads tolerantes)
        
        Returns:
            Lista de recomendaÃ§Ãµes priorizadas
        """
        recommendations = []
        usage = self.analyze_usage()
        
        # 1. RecomendaÃ§Ãµes de downsizing
        for instance in usage.get('underutilized', []):
            rec = self._generate_rightsizing_recommendation(instance, 'down')
            if rec:
                recommendations.append(rec)
        
        # 2. RecomendaÃ§Ãµes de upsizing
        for instance in usage.get('overutilized', []):
            rec = self._generate_rightsizing_recommendation(instance, 'up')
            if rec:
                recommendations.append(rec)
        
        # 3. RecomendaÃ§Ãµes de terminaÃ§Ã£o
        for instance in usage.get('idle_stopped', []):
            recommendations.append({
                'id': f"rec-term-{instance['instance_id']}",
                'type': 'terminate_idle',
                'resource_id': instance['instance_id'],
                'resource_name': instance['name'],
                'title': 'Terminate idle stopped instance',
                'description': f"Instance stopped for {instance['days_stopped']} days. "
                              f"Consider terminating to eliminate storage costs or "
                              f"create an AMI for future use.",
                'estimated_savings': self._estimate_stopped_instance_cost(instance),
                'effort': 'low',
                'risk': 'low',
                'priority': 1
            })
        
        # 4. AnÃ¡lise de Reserved Instances (se houver instÃ¢ncias consistentes)
        ri_recommendations = self._analyze_reserved_instance_opportunity()
        recommendations.extend(ri_recommendations)
        
        # Ordenar por economia estimada
        recommendations.sort(key=lambda r: r.get('estimated_savings', 0), reverse=True)
        
        return recommendations
    
    def get_metrics(self) -> Dict[str, Any]:
        """
        Coleta mÃ©tricas agregadas de EC2 do CloudWatch.
        
        Returns:
            Dict com mÃ©tricas agregadas
        """
        instances = self._get_all_instances()
        running = [i for i in instances if i.is_running]
        
        if not running:
            return {'message': 'No running instances found'}
        
        # Coletar mÃ©tricas de todas as instÃ¢ncias
        all_cpu = []
        all_network_in = []
        all_network_out = []
        
        for instance in running[:20]:  # Limitar para performance
            metrics = self._get_instance_metrics(instance.instance_id)
            if 'cpu_average' in metrics:
                all_cpu.append(metrics['cpu_average'])
            if 'network_in_bytes' in metrics:
                all_network_in.append(metrics['network_in_bytes'])
            if 'network_out_bytes' in metrics:
                all_network_out.append(metrics['network_out_bytes'])
        
        return {
            'timestamp': datetime.utcnow().isoformat(),
            'instances_sampled': len(running[:20]),
            'cpu': {
                'average': statistics.mean(all_cpu) if all_cpu else 0,
                'max': max(all_cpu) if all_cpu else 0,
                'min': min(all_cpu) if all_cpu else 0
            },
            'network': {
                'total_in_bytes': sum(all_network_in),
                'total_out_bytes': sum(all_network_out)
            }
        }
    
    # =========================================================================
    # MÃ‰TODOS PRIVADOS
    # =========================================================================
    
    def _get_all_instances(self) -> List[EC2Instance]:
        """ObtÃ©m todas as instÃ¢ncias EC2."""
        instances = []
        paginator = self._ec2.get_paginator('describe_instances')
        
        for page in paginator.paginate():
            for reservation in page['Reservations']:
                for instance in reservation['Instances']:
                    instances.append(EC2Instance(
                        instance_id=instance['InstanceId'],
                        instance_type=instance['InstanceType'],
                        state=instance['State']['Name'],
                        launch_time=instance['LaunchTime'],
                        availability_zone=instance['Placement']['AvailabilityZone'],
                        vpc_id=instance.get('VpcId'),
                        subnet_id=instance.get('SubnetId'),
                        private_ip=instance.get('PrivateIpAddress'),
                        public_ip=instance.get('PublicIpAddress'),
                        tags={t['Key']: t['Value'] for t in instance.get('Tags', [])},
                        platform=instance.get('Platform', 'linux')
                    ))
        
        return instances
    
    def _get_instance_metrics(
        self,
        instance_id: str,
        period_days: int = 30
    ) -> Dict[str, Any]:
        """Coleta mÃ©tricas CloudWatch de uma instÃ¢ncia."""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=period_days)
        
        try:
            # CPU Utilization
            cpu_response = self._cloudwatch.get_metric_statistics(
                Namespace='AWS/EC2',
                MetricName='CPUUtilization',
                Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
                StartTime=start_time,
                EndTime=end_time,
                Period=86400,  # 1 dia
                Statistics=['Average', 'Maximum']
            )
            
            cpu_datapoints = cpu_response.get('Datapoints', [])
            cpu_avg = statistics.mean([d['Average'] for d in cpu_datapoints]) if cpu_datapoints else 50
            cpu_max = max([d['Maximum'] for d in cpu_datapoints]) if cpu_datapoints else 50
            
            return {
                'instance_id': instance_id,
                'period_days': period_days,
                'cpu_average': round(cpu_avg, 2),
                'cpu_maximum': round(cpu_max, 2),
                'datapoints_count': len(cpu_datapoints)
            }
            
        except Exception as e:
            self.logger.warning(f"Failed to get metrics for {instance_id}: {e}")
            return {'instance_id': instance_id, 'error': str(e)}
    
    def _generate_rightsizing_recommendation(
        self,
        instance: Dict,
        direction: str
    ) -> Optional[Dict]:
        """Gera recomendaÃ§Ã£o de rightsizing."""
        instance_type = instance['instance_type']
        
        # Mapeamento simplificado de tipos
        type_family = instance_type.split('.')[0]
        type_size = instance_type.split('.')[1]
        
        sizes = ['nano', 'micro', 'small', 'medium', 'large', 'xlarge', '2xlarge', '4xlarge']
        
        if type_size not in sizes:
            return None
        
        current_idx = sizes.index(type_size)
        
        if direction == 'down' and current_idx > 0:
            new_size = sizes[current_idx - 1]
            estimated_savings = self._estimate_savings(instance_type, f"{type_family}.{new_size}")
            
            return {
                'id': f"rec-down-{instance['instance_id']}",
                'type': 'rightsizing_down',
                'resource_id': instance['instance_id'],
                'resource_name': instance['name'],
                'title': f"Downsize {instance_type} to {type_family}.{new_size}",
                'description': f"Instance CPU average is {instance['cpu_average']:.1f}%. "
                              f"Consider downsizing from {instance_type} to {type_family}.{new_size}.",
                'current_type': instance_type,
                'recommended_type': f"{type_family}.{new_size}",
                'estimated_savings': estimated_savings,
                'effort': 'medium',
                'risk': 'low',
                'priority': 2
            }
        
        elif direction == 'up' and current_idx < len(sizes) - 1:
            new_size = sizes[current_idx + 1]
            
            return {
                'id': f"rec-up-{instance['instance_id']}",
                'type': 'rightsizing_up',
                'resource_id': instance['instance_id'],
                'resource_name': instance['name'],
                'title': f"Upsize {instance_type} to {type_family}.{new_size}",
                'description': f"Instance CPU average is {instance['cpu_average']:.1f}%. "
                              f"Consider upsizing to prevent performance issues.",
                'current_type': instance_type,
                'recommended_type': f"{type_family}.{new_size}",
                'estimated_savings': 0,  # Upsizing costs more
                'effort': 'medium',
                'risk': 'low',
                'priority': 3
            }
        
        return None
    
    def _estimate_savings(self, current_type: str, new_type: str) -> float:
        """Estima economia mensal de mudanÃ§a de tipo."""
        # PreÃ§os aproximados (USD/hora) - simplificado
        prices = {
            't3.nano': 0.0052,
            't3.micro': 0.0104,
            't3.small': 0.0208,
            't3.medium': 0.0416,
            't3.large': 0.0832,
            't3.xlarge': 0.1664,
            'm5.large': 0.096,
            'm5.xlarge': 0.192,
            'm5.2xlarge': 0.384
        }
        
        current_price = prices.get(current_type, 0.1)
        new_price = prices.get(new_type, 0.05)
        
        hours_per_month = 730
        return round((current_price - new_price) * hours_per_month, 2)
    
    def _estimate_stopped_instance_cost(self, instance: Dict) -> float:
        """Estima custo de instÃ¢ncia parada (EBS volumes)."""
        # Custo mÃ©dio de EBS por instÃ¢ncia parada
        return 5.0  # USD/mÃªs (estimativa conservadora)
    
    def _analyze_reserved_instance_opportunity(self) -> List[Dict]:
        """Analisa oportunidades de Reserved Instances."""
        # ImplementaÃ§Ã£o simplificada
        return []
```

---

# 8. Fluxo de ExecuÃ§Ã£o Completo

## 8.1 Diagrama de SequÃªncia Principal

```mermaid
sequenceDiagram
    participant EB as EventBridge
    participant SF as Step Functions
    participant MAP as Lambda Mapper
    participant W1 as Lambda Worker 1
    participant W2 as Lambda Worker 2
    participant W3 as Lambda Worker N
    participant AGG as Lambda Aggregator
    participant S3 as S3 Bucket
    participant SNS as SNS Topic
    participant AWS as AWS Services
    
    EB->>SF: Trigger scheduled execution
    SF->>MAP: Start MapServices state
    MAP->>MAP: Divide 253 services into batches
    MAP-->>SF: Return 5 batches
    
    SF->>SF: ProcessBatches (Map state)
    
    par Parallel Processing
        SF->>W1: Process Batch 1
        W1->>AWS: Analyze services 1-50
        AWS-->>W1: Service data
        W1->>S3: Save checkpoint
        W1-->>SF: Batch 1 results
        
        SF->>W2: Process Batch 2
        W2->>AWS: Analyze services 51-100
        AWS-->>W2: Service data
        W2->>S3: Save checkpoint
        W2-->>SF: Batch 2 results
        
        SF->>W3: Process Batch N
        W3->>AWS: Analyze services ...
        AWS-->>W3: Service data
        W3->>S3: Save checkpoint
        W3-->>SF: Batch N results
    end
    
    SF->>AGG: Aggregate state
    AGG->>S3: Load all batch results
    S3-->>AGG: Batch data
    AGG->>AGG: Consolidate & prioritize
    AGG->>S3: Save final report
    AGG-->>SF: Aggregation complete
    
    SF->>SNS: Notify state
    SNS-->>SF: Notification sent
    
    SF-->>EB: Execution complete
```

## 8.2 Fluxo de ResiliÃªncia

```mermaid
flowchart TD
    A[Iniciar AnÃ¡lise de ServiÃ§o] --> B{Health Check OK?}
    
    B -->|Sim| C[Executar analyze_usage]
    B -->|NÃ£o| D{Circuit Breaker Status?}
    
    D -->|CLOSED| E[Incrementar Failure Count]
    D -->|OPEN| F[Rejeitar Imediatamente]
    D -->|HALF_OPEN| G[Permitir Teste]
    
    E --> H{Failures >= Threshold?}
    H -->|Sim| I[Abrir Circuit Breaker]
    H -->|NÃ£o| J[Aplicar Retry Policy]
    
    J --> K[Calcular Exponential Backoff]
    K --> L[Adicionar Jitter]
    L --> M[Aguardar Delay]
    M --> A
    
    I --> F
    
    G --> B
    
    C --> N{OperaÃ§Ã£o OK?}
    N -->|Sim| O[get_recommendations]
    N -->|NÃ£o| J
    
    O --> P{OperaÃ§Ã£o OK?}
    P -->|Sim| Q[Salvar Checkpoint]
    P -->|NÃ£o| J
    
    Q --> R[Registrar Sucesso]
    R --> S{Circuit Half-Open?}
    S -->|Sim| T[Fechar Circuit Breaker]
    S -->|NÃ£o| U[PrÃ³ximo ServiÃ§o]
    T --> U
    
    F --> V[Registrar Skip]
    V --> U
    
    style A fill:#4caf50
    style Q fill:#4caf50
    style R fill:#4caf50
    style F fill:#f44336
    style I fill:#ff9800
```

---

# 9. Gerenciamento de Estado com S3

## 9.1 Estrutura S3

```
s3://finops-aws-{account-id}-{region}/
â”‚
â”œâ”€â”€ state/                              # Estado de execuÃ§Ãµes
â”‚   â””â”€â”€ executions/
â”‚       â””â”€â”€ {execution_id}/
â”‚           â”œâ”€â”€ state.json              # Estado principal
â”‚           â””â”€â”€ metadata.json           # Metadados
â”‚
â”œâ”€â”€ checkpoints/                        # Checkpoints por serviÃ§o
â”‚   â””â”€â”€ {execution_id}/
â”‚       â”œâ”€â”€ ec2.json
â”‚       â”œâ”€â”€ lambda.json
â”‚       â”œâ”€â”€ s3.json
â”‚       â””â”€â”€ ... (253 checkpoints)
â”‚
â”œâ”€â”€ reports/                            # RelatÃ³rios finais
â”‚   â”œâ”€â”€ {YYYY}/{MM}/{DD}/
â”‚   â”‚   â””â”€â”€ {execution_id}/
â”‚   â”‚       â”œâ”€â”€ full_report.json        # RelatÃ³rio completo
â”‚   â”‚       â”œâ”€â”€ executive_summary.json  # Resumo executivo
â”‚   â”‚       â””â”€â”€ recommendations.json    # SÃ³ recomendaÃ§Ãµes
â”‚   â””â”€â”€ latest/
â”‚       â”œâ”€â”€ report.json                 # Ãšltimo relatÃ³rio
â”‚       â””â”€â”€ summary.json                # Ãšltimo resumo
â”‚
â””â”€â”€ archives/                           # RelatÃ³rios arquivados
    â””â”€â”€ {YYYY}/{MM}/
        â””â”€â”€ *.json.gz                   # Comprimidos
```

## 9.2 S3StateManager

```python
import json
import boto3
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field, asdict
from datetime import datetime
import uuid

@dataclass
class ExecutionState:
    """Estado de uma execuÃ§Ã£o FinOps."""
    execution_id: str
    started_at: str
    status: str  # 'running', 'completed', 'failed', 'partial'
    services_total: int
    services_completed: int
    services_failed: int
    current_service: Optional[str] = None
    last_checkpoint: Optional[str] = None
    completed_services: List[str] = field(default_factory=list)
    failed_services: List[str] = field(default_factory=list)
    results: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'ExecutionState':
        return cls(**data)


class S3StateManager:
    """
    Gerenciador de estado usando S3.
    
    Responsabilidades:
    - Criar e atualizar estado de execuÃ§Ã£o
    - Salvar checkpoints por serviÃ§o
    - Permitir resumo de execuÃ§Ãµes interrompidas
    - Salvar relatÃ³rios finais
    
    BenefÃ­cios vs DynamoDB:
    - Custo praticamente zero para 100 execuÃ§Ãµes/dia
    - Sem provisionamento de capacidade
    - Simples de implementar
    """
    
    def __init__(
        self,
        bucket_name: str = None,
        region: str = 'us-east-1'
    ):
        self._s3 = boto3.client('s3', region_name=region)
        self._bucket = bucket_name or self._get_default_bucket_name()
    
    def _get_default_bucket_name(self) -> str:
        """ObtÃ©m nome do bucket das env vars ou gera padrÃ£o."""
        import os
        if 'FINOPS_BUCKET' in os.environ:
            return os.environ['FINOPS_BUCKET']
        
        # Gerar nome baseado na conta
        sts = boto3.client('sts')
        account_id = sts.get_caller_identity()['Account']
        return f"finops-aws-{account_id}"
    
    # =========================================================================
    # GERENCIAMENTO DE EXECUÃ‡ÃƒO
    # =========================================================================
    
    def create_execution(self, total_services: int = 253) -> ExecutionState:
        """
        Cria nova execuÃ§Ã£o.
        
        Args:
            total_services: Total de serviÃ§os a processar
            
        Returns:
            ExecutionState nova
        """
        execution_id = f"exec-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"
        
        state = ExecutionState(
            execution_id=execution_id,
            started_at=datetime.utcnow().isoformat(),
            status='running',
            services_total=total_services,
            services_completed=0,
            services_failed=0
        )
        
        self._save_state(state)
        return state
    
    def get_execution(self, execution_id: str) -> Optional[ExecutionState]:
        """ObtÃ©m estado de execuÃ§Ã£o existente."""
        try:
            response = self._s3.get_object(
                Bucket=self._bucket,
                Key=f"state/executions/{execution_id}/state.json"
            )
            data = json.loads(response['Body'].read().decode('utf-8'))
            return ExecutionState.from_dict(data)
        except self._s3.exceptions.NoSuchKey:
            return None
    
    def get_or_create_execution(self, execution_id: str = None) -> ExecutionState:
        """ObtÃ©m execuÃ§Ã£o existente ou cria nova."""
        if execution_id:
            existing = self.get_execution(execution_id)
            if existing:
                return existing
        return self.create_execution()
    
    def update_execution(self, state: ExecutionState):
        """Atualiza estado de execuÃ§Ã£o."""
        state.last_checkpoint = datetime.utcnow().isoformat()
        self._save_state(state)
    
    def complete_execution(
        self,
        state: ExecutionState,
        final_results: Dict[str, Any]
    ):
        """Marca execuÃ§Ã£o como completa."""
        state.status = 'completed' if not state.failed_services else 'partial'
        state.results = final_results
        self._save_state(state)
        
        # Salvar relatÃ³rio final
        self._save_report(state, final_results)
    
    def _save_state(self, state: ExecutionState):
        """Salva estado no S3."""
        self._s3.put_object(
            Bucket=self._bucket,
            Key=f"state/executions/{state.execution_id}/state.json",
            Body=json.dumps(state.to_dict(), indent=2, default=str),
            ContentType='application/json'
        )
    
    # =========================================================================
    # GERENCIAMENTO DE CHECKPOINTS
    # =========================================================================
    
    def save_service_checkpoint(
        self,
        execution_id: str,
        service_name: str,
        result: Dict[str, Any]
    ):
        """
        Salva checkpoint de um serviÃ§o.
        
        Permite resumo em caso de interrupÃ§Ã£o.
        """
        self._s3.put_object(
            Bucket=self._bucket,
            Key=f"checkpoints/{execution_id}/{service_name}.json",
            Body=json.dumps(result, indent=2, default=str),
            ContentType='application/json'
        )
    
    def get_service_checkpoint(
        self,
        execution_id: str,
        service_name: str
    ) -> Optional[Dict]:
        """ObtÃ©m checkpoint de serviÃ§o se existir."""
        try:
            response = self._s3.get_object(
                Bucket=self._bucket,
                Key=f"checkpoints/{execution_id}/{service_name}.json"
            )
            return json.loads(response['Body'].read().decode('utf-8'))
        except self._s3.exceptions.NoSuchKey:
            return None
    
    def is_service_completed(
        self,
        execution_id: str,
        service_name: str
    ) -> bool:
        """Verifica se serviÃ§o jÃ¡ foi processado."""
        try:
            self._s3.head_object(
                Bucket=self._bucket,
                Key=f"checkpoints/{execution_id}/{service_name}.json"
            )
            return True
        except:
            return False
    
    def get_all_checkpoints(self, execution_id: str) -> Dict[str, Dict]:
        """ObtÃ©m todos os checkpoints de uma execuÃ§Ã£o."""
        checkpoints = {}
        
        paginator = self._s3.get_paginator('list_objects_v2')
        for page in paginator.paginate(
            Bucket=self._bucket,
            Prefix=f"checkpoints/{execution_id}/"
        ):
            for obj in page.get('Contents', []):
                key = obj['Key']
                service_name = key.split('/')[-1].replace('.json', '')
                checkpoints[service_name] = self.get_service_checkpoint(
                    execution_id, service_name
                )
        
        return checkpoints
    
    # =========================================================================
    # GERENCIAMENTO DE RELATÃ“RIOS
    # =========================================================================
    
    def _save_report(self, state: ExecutionState, results: Dict):
        """Salva relatÃ³rio final."""
        timestamp = datetime.utcnow()
        date_path = timestamp.strftime('%Y/%m/%d')
        
        # RelatÃ³rio completo
        self._s3.put_object(
            Bucket=self._bucket,
            Key=f"reports/{date_path}/{state.execution_id}/full_report.json",
            Body=json.dumps(results, indent=2, default=str),
            ContentType='application/json'
        )
        
        # Resumo executivo
        summary = self._generate_summary(state, results)
        self._s3.put_object(
            Bucket=self._bucket,
            Key=f"reports/{date_path}/{state.execution_id}/executive_summary.json",
            Body=json.dumps(summary, indent=2, default=str),
            ContentType='application/json'
        )
        
        # Atualizar "latest"
        self._s3.put_object(
            Bucket=self._bucket,
            Key="reports/latest/report.json",
            Body=json.dumps(results, indent=2, default=str),
            ContentType='application/json'
        )
    
    def _generate_summary(
        self,
        state: ExecutionState,
        results: Dict
    ) -> Dict:
        """Gera resumo executivo."""
        return {
            'execution_id': state.execution_id,
            'timestamp': datetime.utcnow().isoformat(),
            'status': state.status,
            'services': {
                'total': state.services_total,
                'completed': state.services_completed,
                'failed': state.services_failed,
                'success_rate': f"{(state.services_completed/state.services_total)*100:.1f}%"
            },
            'recommendations': {
                'total': len(results.get('recommendations', [])),
                'top_5': results.get('recommendations', [])[:5]
            },
            'potential_savings': sum(
                r.get('estimated_savings', 0)
                for r in results.get('recommendations', [])
            )
        }
    
    def get_latest_report(self) -> Optional[Dict]:
        """ObtÃ©m Ãºltimo relatÃ³rio."""
        try:
            response = self._s3.get_object(
                Bucket=self._bucket,
                Key="reports/latest/report.json"
            )
            return json.loads(response['Body'].read().decode('utf-8'))
        except:
            return None
```

---

# 10. ResiliÃªncia e Mecanismos de Retry

(Ver seÃ§Ã£o 4.4 e 4.5 para implementaÃ§Ãµes detalhadas de Circuit Breaker e Retry)

## 10.1 EstratÃ©gia de ResiliÃªncia

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAMADAS DE RESILIÃŠNCIA                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Camada 1: RETRY HANDLER                                                    â”‚
â”‚  â”œâ”€â”€ Exponential backoff (1s, 2s, 4s, 8s, ...)                             â”‚
â”‚  â”œâ”€â”€ Jitter para evitar thundering herd                                    â”‚
â”‚  â”œâ”€â”€ MÃ¡ximo 3 tentativas por padrÃ£o                                        â”‚
â”‚  â””â”€â”€ Reconhece erros transitÃ³rios AWS (Throttling, ServiceUnavailable)    â”‚
â”‚                                                                             â”‚
â”‚  Camada 2: CIRCUIT BREAKER                                                  â”‚
â”‚  â”œâ”€â”€ Abre apÃ³s 5 falhas consecutivas                                       â”‚
â”‚  â”œâ”€â”€ Timeout de recuperaÃ§Ã£o: 30 segundos                                   â”‚
â”‚  â”œâ”€â”€ Half-open permite 3 chamadas de teste                                 â”‚
â”‚  â””â”€â”€ Previne sobrecarga de serviÃ§os com problemas                          â”‚
â”‚                                                                             â”‚
â”‚  Camada 3: CHECKPOINTING                                                    â”‚
â”‚  â”œâ”€â”€ Salva progresso no S3 apÃ³s cada serviÃ§o                               â”‚
â”‚  â”œâ”€â”€ Permite resumo de execuÃ§Ãµes interrompidas                             â”‚
â”‚  â””â”€â”€ Evita reprocessamento de serviÃ§os jÃ¡ analisados                       â”‚
â”‚                                                                             â”‚
â”‚  Camada 4: STEP FUNCTIONS RETRY                                             â”‚
â”‚  â”œâ”€â”€ Retry nativo do Step Functions                                        â”‚
â”‚  â”œâ”€â”€ Catch para erros nÃ£o recuperÃ¡veis                                     â”‚
â”‚  â””â”€â”€ Dead Letter Queue para anÃ¡lise posterior                              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 11. IntegraÃ§Ã£o AWS Lambda e Step Functions

## 11.1 ConfiguraÃ§Ã£o Lambda

```python
# lambda_handler.py - Handler principal

import os
import json
import logging
from typing import Dict, Any

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    Handler principal do AWS Lambda para FinOps.
    
    Eventos suportados:
    - Scheduled (EventBridge): ExecuÃ§Ã£o agendada
    - Step Functions: Chamada do state machine
    - API Gateway: RequisiÃ§Ã£o REST
    - Direct Invoke: InvocaÃ§Ã£o programÃ¡tica
    
    Environment Variables:
    - AWS_REGION: RegiÃ£o AWS
    - FINOPS_BUCKET: Bucket S3 para estado
    - LOG_LEVEL: NÃ­vel de log (INFO, DEBUG, etc.)
    
    Returns:
        Dict com statusCode e body JSON
    """
    try:
        # Configurar logging
        log_level = os.environ.get('LOG_LEVEL', 'INFO')
        logger.setLevel(getattr(logging, log_level))
        
        logger.info(f"Event received: {json.dumps(event)[:500]}")
        
        # Identificar tipo de evento
        event_type = _identify_event_type(event)
        logger.info(f"Event type: {event_type}")
        
        # Processar baseado no tipo
        if event_type == 'step_functions_mapper':
            return _handle_mapper(event, context)
        elif event_type == 'step_functions_worker':
            return _handle_worker(event, context)
        elif event_type == 'step_functions_aggregator':
            return _handle_aggregator(event, context)
        elif event_type == 'api_gateway':
            return _handle_api_request(event, context)
        else:
            return _handle_scheduled(event, context)
            
    except Exception as e:
        logger.exception("Lambda execution failed")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'type': type(e).__name__
            })
        }


def _identify_event_type(event: Dict) -> str:
    """Identifica tipo de evento."""
    if 'httpMethod' in event:
        return 'api_gateway'
    if 'task' in event and event['task'] == 'map':
        return 'step_functions_mapper'
    if 'batch_id' in event or 'services' in event:
        return 'step_functions_worker'
    if 'batchResults' in event:
        return 'step_functions_aggregator'
    return 'scheduled'


def _handle_mapper(event: Dict, context: Any) -> Dict:
    """Handler para Lambda Mapper."""
    from core.factories import ServiceFactory
    
    factory = ServiceFactory()
    all_services = list(factory.get_all_services().keys())
    
    # Dividir em 5 batches
    batch_size = 50
    batches = []
    
    for i in range(0, len(all_services), batch_size):
        batches.append({
            'batch_id': len(batches),
            'services': all_services[i:i+batch_size],
            'execution_id': event.get('execution_id', str(uuid.uuid4()))
        })
    
    return {
        'batches': batches,
        'total_services': len(all_services),
        'total_batches': len(batches)
    }


def _handle_worker(event: Dict, context: Any) -> Dict:
    """Handler para Lambda Worker."""
    from core.factories import ServiceFactory, AWSClientFactory
    from core.s3_state_manager import S3StateManager
    from core.resilient_executor import ResilientExecutor
    
    batch = event['services']
    execution_id = event['execution_id']
    
    client_factory = AWSClientFactory()
    service_factory = ServiceFactory(client_factory)
    state_manager = S3StateManager()
    executor = ResilientExecutor(service_factory, state_manager)
    
    results = []
    
    for service_name in batch:
        try:
            # Verificar checkpoint
            if state_manager.is_service_completed(execution_id, service_name):
                checkpoint = state_manager.get_service_checkpoint(
                    execution_id, service_name
                )
                results.append(checkpoint)
                continue
            
            # Processar serviÃ§o
            service = service_factory.get_service(service_name)
            result = service.execute_full_analysis()
            
            # Salvar checkpoint
            state_manager.save_service_checkpoint(
                execution_id, service_name, result
            )
            results.append(result)
            
        except Exception as e:
            logger.error(f"Failed to process {service_name}: {e}")
            results.append({
                'service': service_name,
                'status': 'failed',
                'error': str(e)
            })
    
    return {
        'batch_id': event['batch_id'],
        'results': results,
        'completed': len([r for r in results if r.get('status') != 'failed']),
        'failed': len([r for r in results if r.get('status') == 'failed'])
    }


def _handle_aggregator(event: Dict, context: Any) -> Dict:
    """Handler para Lambda Aggregator."""
    # ImplementaÃ§Ã£o na seÃ§Ã£o 3.4.3
    pass


def _handle_api_request(event: Dict, context: Any) -> Dict:
    """Handler para requisiÃ§Ãµes API Gateway."""
    from core.api_gateway_handler import APIGatewayHandler
    
    handler = APIGatewayHandler()
    return handler.handle(event, context)


def _handle_scheduled(event: Dict, context: Any) -> Dict:
    """Handler para execuÃ§Ã£o agendada."""
    # Iniciar Step Functions execution
    sfn = boto3.client('stepfunctions')
    
    response = sfn.start_execution(
        stateMachineArn=os.environ['STATE_MACHINE_ARN'],
        name=f"finops-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}",
        input=json.dumps({'triggered_by': 'scheduled'})
    )
    
    return {
        'statusCode': 200,
        'body': json.dumps({
            'message': 'Execution started',
            'execution_arn': response['executionArn']
        })
    }
```

---

# 12. SeguranÃ§a e Compliance

## 12.1 PrincÃ­pios de SeguranÃ§a

| PrincÃ­pio | ImplementaÃ§Ã£o | VerificaÃ§Ã£o |
|-----------|---------------|-------------|
| **Least Privilege** | IAM policies mÃ­nimas | Terraform valida policies |
| **Encryption at Rest** | S3 SSE-KMS, EBS encryption | AWS Config rules |
| **Encryption in Transit** | TLS 1.2+ obrigatÃ³rio | Security Hub findings |
| **No Hardcoded Secrets** | Secrets Manager, Env vars | Git secrets scanning |
| **Audit Trail** | CloudTrail logging | Log analysis |
| **Network Isolation** | VPC Endpoints opcionais | VPC Flow Logs |

## 12.2 IAM Policy MÃ­nima

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "ReadOnlyServicesAccess",
            "Effect": "Allow",
            "Action": [
                "ec2:Describe*",
                "rds:Describe*",
                "s3:GetBucket*",
                "s3:ListBucket",
                "s3:ListAllMyBuckets",
                "lambda:List*",
                "lambda:Get*",
                "ecs:Describe*",
                "ecs:List*",
                "eks:Describe*",
                "eks:List*",
                "elasticache:Describe*",
                "dynamodb:Describe*",
                "dynamodb:List*",
                "cloudwatch:GetMetricData",
                "cloudwatch:GetMetricStatistics",
                "cloudwatch:ListMetrics",
                "ce:GetCostAndUsage",
                "ce:GetReservationUtilization",
                "ce:GetSavingsPlansUtilization"
            ],
            "Resource": "*"
        },
        {
            "Sid": "S3StateAccess",
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:ListBucket",
                "s3:DeleteObject"
            ],
            "Resource": [
                "arn:aws:s3:::finops-aws-*",
                "arn:aws:s3:::finops-aws-*/*"
            ]
        },
        {
            "Sid": "KMSAccess",
            "Effect": "Allow",
            "Action": [
                "kms:Decrypt",
                "kms:Encrypt",
                "kms:GenerateDataKey"
            ],
            "Resource": "arn:aws:kms:*:*:key/*",
            "Condition": {
                "StringEquals": {
                    "kms:ViaService": "s3.*.amazonaws.com"
                }
            }
        },
        {
            "Sid": "CloudWatchLogsAccess",
            "Effect": "Allow",
            "Action": [
                "logs:CreateLogGroup",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": "arn:aws:logs:*:*:log-group:/aws/lambda/finops-*"
        },
        {
            "Sid": "StepFunctionsExecution",
            "Effect": "Allow",
            "Action": [
                "states:StartExecution",
                "states:SendTaskSuccess",
                "states:SendTaskFailure"
            ],
            "Resource": "arn:aws:states:*:*:stateMachine:finops-*"
        },
        {
            "Sid": "SNSPublish",
            "Effect": "Allow",
            "Action": "sns:Publish",
            "Resource": "arn:aws:sns:*:*:finops-*"
        }
    ]
}
```

---

# 13. Testes e Qualidade de Software

## 13.1 MÃ©tricas de Qualidade

| MÃ©trica | Valor | Meta |
|---------|-------|------|
| **Total de Testes** | 2.013 | 2.000+ |
| **Taxa de Sucesso** | 99,6% | 99%+ |
| **Testes Passando** | 2.006 | - |
| **Testes Skipped** | 7 | <10 |
| **Cobertura de CÃ³digo** | ~90% | 85%+ |
| **QA Comprehensive** | 78 cenÃ¡rios | 75+ |

## 13.2 PirÃ¢mide de Testes

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   E2E   â”‚  5%
                    â”‚  Tests  â”‚
                 â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”
                 â”‚  Integration  â”‚  20%
                 â”‚     Tests     â”‚
              â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”
              â”‚      Unit Tests     â”‚  75%
              â”‚                     â”‚
              â”‚  2.013 testes       â”‚
              â”‚  253 serviÃ§os       â”‚
              â”‚  14 fases           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 13.3 Executando Testes

```bash
# Todos os testes
pytest tests/unit/ -v

# Com cobertura
pytest tests/unit/ --cov=src/finops_aws --cov-report=html

# Testes paralelos
pytest tests/unit/ -n auto

# Testes especÃ­ficos
pytest tests/unit/test_phase1_services.py -v
pytest tests/unit/test_qa_comprehensive.py -v

# Testes de integraÃ§Ã£o (requer AWS)
pytest tests/integration/ -v --aws

# Demo local com mocks
python run_local_demo.py 1

# Executar testes via demo
python run_local_demo.py 2
```

---

# 14. Infraestrutura como CÃ³digo (Terraform)

## 14.1 VisÃ£o Geral

A infraestrutura Ã© definida em **3.006 linhas** de cÃ³digo Terraform:

```
infrastructure/terraform/
â”œâ”€â”€ main.tf              # ConfiguraÃ§Ã£o principal, providers
â”œâ”€â”€ variables.tf         # VariÃ¡veis de entrada
â”œâ”€â”€ outputs.tf           # Outputs
â”œâ”€â”€ lambda.tf            # FunÃ§Ãµes Lambda (Mapper, Worker, Aggregator)
â”œâ”€â”€ step_functions.tf    # State Machine
â”œâ”€â”€ iam.tf              # Roles e policies
â”œâ”€â”€ s3.tf               # Buckets S3
â”œâ”€â”€ eventbridge.tf      # Schedules
â”œâ”€â”€ kms.tf              # Chaves KMS
â”œâ”€â”€ sqs.tf              # Dead Letter Queue
â”œâ”€â”€ sns.tf              # TÃ³pico de notificaÃ§Ãµes
â”œâ”€â”€ monitoring.tf       # CloudWatch Dashboard e Alarms
â””â”€â”€ README_TERRAFORM.md  # DocumentaÃ§Ã£o
```

## 14.2 Deploy

```bash
cd infrastructure/terraform

# Configurar variÃ¡veis
cp terraform.tfvars.example terraform.tfvars
# Editar terraform.tfvars

# Inicializar
terraform init

# Validar
terraform validate

# Planejar
terraform plan -out=tfplan

# Aplicar
terraform apply tfplan

# Destruir (quando necessÃ¡rio)
terraform destroy
```

## 14.3 Custo Estimado

| Recurso | Quantidade | Custo/mÃªs |
|---------|------------|-----------|
| Lambda (Mapper) | 100 invocaÃ§Ãµes | $0.01 |
| Lambda (Workers) | 500 invocaÃ§Ãµes | $0.10 |
| Lambda (Aggregator) | 100 invocaÃ§Ãµes | $0.01 |
| Step Functions | 100 execuÃ§Ãµes | $2.50 |
| S3 | ~100MB | $0.02 |
| CloudWatch Logs | ~1GB | $0.50 |
| **TOTAL** | - | **~$3.16/mÃªs** |

---

# 15. Modelos de Dados e Dataclasses

(Ver implementaÃ§Ãµes detalhadas nas seÃ§Ãµes anteriores)

---

# 16. APIs e Interfaces

## 16.1 API REST (API Gateway)

```yaml
openapi: 3.0.0
info:
  title: FinOps AWS API
  version: 1.0.0

paths:
  /analyze:
    post:
      summary: Inicia anÃ¡lise completa
      responses:
        200:
          description: ExecuÃ§Ã£o iniciada
          
  /status/{execution_id}:
    get:
      summary: Status de execuÃ§Ã£o
      parameters:
        - name: execution_id
          in: path
          required: true
          
  /report/{execution_id}:
    get:
      summary: ObtÃ©m relatÃ³rio
      
  /recommendations:
    get:
      summary: Lista recomendaÃ§Ãµes
      parameters:
        - name: min_savings
          in: query
          schema:
            type: number
        - name: category
          in: query
          schema:
            type: string
```

---

# 17. AI Consultant - IntegraÃ§Ã£o Amazon Q Business

## 17.1 VisÃ£o Geral

O mÃ³dulo **AI Consultant** integra o FinOps AWS com o Amazon Q Business para gerar relatÃ³rios inteligentes em linguagem natural. O sistema transforma dados brutos de custo em anÃ¡lises executivas personalizadas para diferentes pÃºblicos.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI CONSULTANT ARCHITECTURE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Aggregator â”‚ â”€â”€> â”‚ DataFormatterâ”‚ â”€â”€> â”‚  PromptBuilder â”‚               â”‚
â”‚  â”‚   Lambda    â”‚     â”‚             â”‚     â”‚   (4 Personas) â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                  â”‚                          â”‚
â”‚                                                  â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     AMAZON Q BUSINESS                                â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚Applicationâ”‚  â”‚   Index   â”‚  â”‚  Retrieverâ”‚  â”‚DataSource â”‚        â”‚   â”‚
â”‚  â”‚  â”‚(FinOps AI)â”‚  â”‚(Knowledge)â”‚  â”‚  (Native) â”‚  â”‚   (S3)    â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚                          â”‚
â”‚                                                  â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ResponseParserâ”‚ â”€â”€> â”‚ReportStructurerâ”‚â”€â”€>â”‚  Delivery   â”‚                 â”‚
â”‚  â”‚             â”‚     â”‚ (MD/HTML/JSON)â”‚    â”‚ (Email/Slack)â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 17.2 Componentes do MÃ³dulo

### QBusinessClient

Cliente principal para interaÃ§Ã£o com Amazon Q Business API:

```python
from finops_aws.ai_consultant import QBusinessClient, QBusinessConfig

config = QBusinessConfig.from_env()
client = QBusinessClient(config)

# Chat sÃ­ncrono
response = client.chat("Analise os custos de EC2 do Ãºltimo mÃªs")
print(response.message)
```

### PromptBuilder

Construtor de prompts otimizados para diferentes personas:

```python
from finops_aws.ai_consultant import PromptBuilder, PromptPersona

builder = PromptBuilder()
prompt = builder.build_analysis_prompt(
    cost_data={"total_cost": 47523.89, ...},
    period="Nov 2024",
    persona=PromptPersona.EXECUTIVE
)
```

### Personas DisponÃ­veis

| Persona | Foco | Detalhes TÃ©cnicos | Comandos |
|---------|------|-------------------|----------|
| **EXECUTIVE** | ROI, tendÃªncias, decisÃµes | NÃ£o | NÃ£o |
| **CTO** | Arquitetura, trade-offs | Sim | NÃ£o |
| **DEVOPS** | ImplementaÃ§Ã£o, scripts | Sim | Sim |
| **ANALYST** | MÃ©tricas, KPIs, benchmarks | Sim | Sim |

## 17.3 Fluxo de GeraÃ§Ã£o de RelatÃ³rio

```mermaid
sequenceDiagram
    participant A as Aggregator Lambda
    participant F as DataFormatter
    participant Q as Amazon Q Business
    participant P as ResponseParser
    participant D as Delivery

    A->>F: cost_report
    F->>F: format_cost_report()
    F->>Q: PromptBuilder.build_analysis_prompt()
    Q->>Q: chat_sync()
    Q->>P: response.message
    P->>P: parse()
    P->>D: structured_report
    D->>D: send_email() / send_slack()
```

## 17.4 Knowledge Base

Documentos indexados para enriquecer respostas:

- `aws_best_practices.md` - Melhores prÃ¡ticas de otimizaÃ§Ã£o AWS
- `finops_framework.md` - Framework FinOps e metodologia

## 17.5 ConfiguraÃ§Ã£o Terraform

```hcl
# Habilitar Q Business
variable "enable_q_business" {
  default = true
}

# ARN do IAM Identity Center (obrigatÃ³rio)
variable "identity_center_instance_arn" {
  description = "ARN do IAM Identity Center"
}
```

Recursos criados:
- Q Business Application
- Q Business Index (Enterprise)
- Q Business Retriever (Native)
- Q Business Data Source (S3)
- Lambda para geraÃ§Ã£o de relatÃ³rios

## 17.6 Templates de Prompts para Reducao de Custos

O sistema utiliza prompts estruturados e otimizados para gerar recomendacoes de reducao de custos. Cada prompt e composto por:

1. **Contexto do Sistema** - Define o papel do AI como consultor FinOps senior
2. **Dados de Custo** - JSON com custos consolidados do periodo
3. **Template da Persona** - Instrucoes especificas para a audiencia
4. **Secoes Solicitadas** - Lista de analises a incluir

### Contexto do Sistema (Comum a Todos)

```markdown
Voce e um consultor senior de FinOps especializado em AWS, com mais de 15 anos 
de experiencia em otimizacao de custos cloud. Voce trabalha para uma empresa 
de consultoria de excelencia e esta produzindo uma analise para um cliente 
enterprise.

Seu conhecimento inclui:
- Todos os 253 servicos AWS e seus modelos de precificacao
- AWS Well-Architected Framework (Cost Optimization Pillar)
- FinOps Framework e melhores praticas
- Estrategias de Reserved Instances, Savings Plans e Spot
- Rightsizing, automacao e governanca de custos
```

### Template EXECUTIVE (CEO/CFO)

Foco em ROI e decisoes estrategicas:

```markdown
### Estrutura do Relatorio

#### 1. RESUMO EXECUTIVO (3 paragrafos)
- Gasto total do periodo em USD
- Variacao percentual vs periodo anterior
- Uma acao prioritaria com maior ROI

#### 2. TOP 5 OPORTUNIDADES DE ECONOMIA
| Oportunidade | Economia/Mes | Economia/Ano | Esforco | Prazo |

#### 3. TENDENCIAS E PROJECOES
- Projecao para proximos 3 meses
- Comparativo YoY

#### 4. RISCOS E ALERTAS
| Risco | Probabilidade | Impacto | Acao Preventiva |

#### 5. CONCLUSAO E PROXIMOS PASSOS
- 3 acoes prioritarias para o proximo mes
- Economia total capturavel
```

### Template OPERATIONAL (DevOps/SRE)

Foco em comandos AWS CLI e scripts prontos:

```markdown
#### 2. RECURSOS PARA ACAO IMEDIATA

RECURSO: i-0abc123def456
SERVICO: EC2
CUSTO ATUAL: $450/mes
UTILIZACAO: 8%
ACAO: Rightsizing para t3.medium
ECONOMIA: $320/mes

COMANDOS:
```bash
aws ec2 stop-instances --instance-ids i-0abc123def456
aws ec2 modify-instance-attribute --instance-id i-0abc123def456 \
  --instance-type '{"Value": "t3.medium"}'
aws ec2 start-instances --instance-ids i-0abc123def456
```

#### 7. SCRIPTS DE AUTOMACAO

```python
#!/usr/bin/env python3
def get_low_cpu_instances(threshold=10):
    # Script completo para identificar recursos subutilizados
```
```

### Template ANALYST (FinOps Analyst)

Foco em metricas, KPIs e benchmarks:

```markdown
#### 1. DASHBOARD DE METRICAS

| KPI | Valor Atual | Anterior | Delta% | Meta | Status |
|-----|-------------|----------|--------|------|--------|
| Custo Total | $47,523 | $42,100 | +12.9% | $45,000 | Vermelho |
| Cobertura RI/SP | 45% | 42% | +3% | 70% | Amarelo |
| Waste Ratio | 8.2% | 9.1% | -0.9% | <5% | Amarelo |

#### 4. ANALISE DE WASTE

| Categoria | Quantidade | Custo/Mes | % do Servico |
|-----------|------------|-----------|--------------|
| EC2 subutilizados | 12 | $1,840 | 9.9% |
| EBS nao anexados | 28 | $420 | 15.2% |

#### 10. RECOMENDACOES PRIORIZADAS

| # | Recomendacao | Economia/Mes | Esforco | Score | Prazo |
|---|--------------|--------------|---------|-------|-------|
| 1 | Rightsizing EC2 | $2,100 | Baixo | 10 | 7d |
| 2 | Deletar EBS orfaos | $420 | Baixo | 9 | 3d |
```

### Arquivos de Origem

| Arquivo | Descricao |
|---------|-----------|
| `prompts/templates/executive.py` | Template para CEO/CFO |
| `prompts/templates/technical.py` | Template para CTO |
| `prompts/templates/operational.py` | Template para DevOps/SRE |
| `prompts/templates/analyst.py` | Template para FinOps Analyst |
| `prompts/builder.py` | Construtor principal de prompts |
| `prompts/personas.py` | Configuracao de personas |

> **Documentacao Completa**: Consulte `docs/PROMPTS_AMAZON_Q.md` para os templates completos de cada persona.

---

# 18. Performance e OtimizaÃ§Ãµes

## 17.1 OtimizaÃ§Ãµes Implementadas

| OtimizaÃ§Ã£o | ImplementaÃ§Ã£o | Impacto |
|------------|---------------|---------|
| **Lazy Loading** | ServiÃ§os criados sob demanda | -50% memÃ³ria |
| **Connection Pooling** | boto3 clients cached | -30% latÃªncia |
| **Parallel Processing** | Step Functions Map | 5x throughput |
| **Checkpointing** | Resume apÃ³s falha | 100% confiabilidade |
| **Batch Processing** | 50 serviÃ§os/worker | Otimizado |

---

# 18. Troubleshooting e Debugging

## 18.1 Problemas Comuns

| Problema | Causa | SoluÃ§Ã£o |
|----------|-------|---------|
| Timeout Lambda | Muitos serviÃ§os | Aumentar batch size |
| Throttling AWS | Rate limit | Ajustar retry policy |
| Memory Error | Resultados grandes | Chunking de dados |
| Permission Denied | IAM policy | Verificar policies |

## 18.2 Logs e MÃ©tricas

```bash
# CloudWatch Logs
aws logs tail /aws/lambda/finops-worker --follow

# MÃ©tricas Lambda
aws cloudwatch get-metric-statistics \
    --namespace AWS/Lambda \
    --metric-name Duration \
    --dimensions Name=FunctionName,Value=finops-worker \
    --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
    --period 300 \
    --statistics Average
```

---

# 19. ApÃªndices TÃ©cnicos

## A. GlossÃ¡rio TÃ©cnico

| Termo | DefiniÃ§Ã£o |
|-------|-----------|
| **FinOps** | Financial Operations - prÃ¡ticas de gestÃ£o financeira em cloud |
| **Rightsizing** | Ajustar tamanho de recursos ao uso real |
| **Reserved Instance** | InstÃ¢ncia com desconto por compromisso de uso |
| **Spot Instance** | InstÃ¢ncia com desconto por capacidade ociosa |
| **Circuit Breaker** | PadrÃ£o para prevenir falhas em cascata |
| **Exponential Backoff** | EstratÃ©gia de retry com delay crescente |
| **Jitter** | VariaÃ§Ã£o aleatÃ³ria para evitar sincronizaÃ§Ã£o |

## B. ReferÃªncias

- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)
- [FinOps Foundation](https://www.finops.org/)
- [Clean Architecture - Robert C. Martin](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [Domain-Driven Design - Eric Evans](https://domainlanguage.com/ddd/)
- [AWS Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html)

---

*Documento TÃ©cnico - FinOps AWS Enterprise Solution*
*VersÃ£o: 2.0*
*Ãšltima AtualizaÃ§Ã£o: Dezembro 2025*
*Autor: Equipe de Engenharia FinOps AWS*
